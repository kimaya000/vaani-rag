# Vaani-rag: Multilingual Audio Query System for Indian Languages Using Hybrid Language Detection and RAG-based Document Retrieval

India’s remarkable linguistic diversity, with 22 official languages listed in the Eighth Schedule of the Constitution and hundreds of dialects spoken across its regions, poses a persistent challenge in cross-language communication—particularly when interfacing with professional, English-dominated documentation. To bridge this gap, we developed a comprehensive multilingual query system that detects spoken languages and returns contextually relevant answers from professional documents in the speaker’s native language.
At the core of the system lies a language identification module, trained on richly diverse data—including the ‘Vaani’ dataset from the Indian Institute of Science, which spans over 54 languages, 80 districts, and 84,617 speakers. The dataset, funded by Google, reflects the authentic linguistic patterns of Indian speakers, making it an excellent foundation for language classification in real-world settings.
Audio inputs are pre-processed using MFCC feature extraction, SMOTE for dataset balancing, and StandardScaler for normalization. Various machine learning and deep learning models—including Random Forest, CNN, LSTM, BiLSTM, and Multi-Head Attention—were evaluated. Our best-performing models are hybrid architectures like CNN+BiLSTM+MHA, along with ensemble techniques that combine the strengths of multiple approaches for superior accuracy in language detection.
Once the spoken language is identified, it is transcribed using the Sarvam AI speech-to-text API, which supports 10 major Indian languages. Sarvam AI, an organization committed to democratizing GenAI for India, provides robust, high-performance, and cost-effective transcription capabilities tailored to the Indian linguistic landscape.
The transcribed text is then processed by a Retrieval-Augmented Generation (RAG) system, which detects the transcript’s language and retrieves relevant information from English-language documents. It translates the responses back into the user's language, allowing culturally relevant and accessible communication.
By integrating state-of-the-art AI technologies, linguistic data, and culturally aware design, this project seeks to empower millions of Indians by providing them with voice-enabled, multilingual access to critical information, bridging linguistic divides and enabling truly inclusive digital participation.
