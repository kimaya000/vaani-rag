{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snxfg1adL3Zb",
        "outputId": "829349e1-6d8e-47a3-b005-2e6e237e25a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout, Input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "# prompt: mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# 1️⃣ Load Data from CSV\n",
        "# ==============================\n",
        "csv_file_path = \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/merged_data.csv\"  # Update with your file path\n",
        "df = pd.read_csv(csv_file_path)\n",
        "print(df.columns)\n",
        "\n",
        "# ==============================\n",
        "# 2️⃣ Prepare Data (Separate Features & Labels)\n",
        "# ==============================\n",
        "X = df.drop(columns=['id', 'filename', 'file_url', 'state', 'gender', 'pincode', 'district',\n",
        "       'stayYears', 'assertLanguage', 'languagesSpoken'])  # Features\n",
        "y = df['state']  # Target variable (predicting state)\n",
        "\n",
        "# Encode labels (convert state names to numbers)\n",
        "state_encoder = LabelEncoder()\n",
        "y_encoded = state_encoder.fit_transform(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_1KYVvvMQil",
        "outputId": "9b33aae7-3c3f-4e55-b3f2-70e11eb4c3cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'filename', 'file_url', 'state', 'gender', 'pincode', 'district',\n",
            "       'stayYears', 'assertLanguage', 'languagesSpoken', 'feature_0',\n",
            "       'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5',\n",
            "       'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10',\n",
            "       'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15',\n",
            "       'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20',\n",
            "       'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25',\n",
            "       'feature_26', 'feature_27', 'feature_28', 'feature_29', 'feature_30',\n",
            "       'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_35',\n",
            "       'feature_36', 'feature_37'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: show me classes of state encoder\n",
        "\n",
        "# Get the unique classes (states) from the encoded labels\n",
        "state_classes = list(state_encoder.classes_)\n",
        "\n",
        "print(\"State Classes:\")\n",
        "state_classes\n",
        "\n",
        "# You can access the numerical representation of each state using:\n",
        "# state_encoder.transform(['Maharashtra', 'Karnataka'])\n",
        "\n",
        "# You can get the original state name using:\n",
        "# state_encoder.inverse_transform([0, 1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4AGfPS2MRi7",
        "outputId": "08be980c-8e5d-4f00-fdca-738af16df677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State Classes:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AndhraPradesh',\n",
              " 'Bihar',\n",
              " 'Chhattisgarh',\n",
              " 'Goa',\n",
              " 'Jharkhand',\n",
              " 'Karnataka',\n",
              " 'Maharashtra',\n",
              " 'Rajasthan',\n",
              " 'Telangana',\n",
              " 'UttarPradesh',\n",
              " 'WestBengal']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "save_path = \"/content/drive/My Drive/state_encoder.pkl\"\n",
        "\n",
        "# Save the LabelEncoder correctly\n",
        "with open(save_path, \"wb\") as file:\n",
        "    pickle.dump(state_encoder, file)  # ✅ Pass the encoder and the file object\n",
        "\n",
        "# Load the LabelEncoder\n",
        "with open(save_path, \"rb\") as file:\n",
        "    loaded_encoder = pickle.load(file)\n",
        "\n",
        "# Test the loaded encoder\n",
        "print(loaded_encoder.classes_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G4nqqIfWe_g",
        "outputId": "159522cf-a1f2-4575-b672-bcc70b1efbcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AndhraPradesh' 'Bihar' 'Chhattisgarh' 'Goa' 'Jharkhand' 'Karnataka'\n",
            " 'Maharashtra' 'Rajasthan' 'Telangana' 'UttarPradesh' 'WestBengal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "save_path = \"/content/drive/My Drive/language_encoder.pkl\"\n",
        "\n",
        "# Save the LabelEncoder correctly\n",
        "with open(save_path, \"wb\") as file:\n",
        "    pickle.dump(language_encoder, file)  # ✅ Pass the encoder and the file object\n",
        "\n",
        "# Load the LabelEncoder\n",
        "with open(save_path, \"rb\") as file:\n",
        "    lang_encoder = pickle.load(file)\n",
        "\n",
        "# Test the loaded encoder\n",
        "print(lang_encoder.classes_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuWs291ZX08K",
        "outputId": "1da94f22-c76d-4798-8789-ed8ac795213b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BENGALI' 'BHATRI' 'CHATTISGARHI' 'GONDI' 'HALBI' 'HINDI' 'KANNADA'\n",
            " 'KHORTHA' 'KONKANI' 'MAITHILI' 'MARATHI' 'MARWARI' 'RAJASTHANI' 'TELUGU'\n",
            " 'URDU']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "save_path = \"/content/drive/My Drive/state_encoder.pkl\"\n",
        "\n",
        "# Save the LabelEncoder correctly\n",
        "with open(save_path, \"wb\") as file:\n",
        "    pickle.dump(state_encoder, file)  # ✅ Pass the encoder and the file object\n",
        "\n",
        "# Load the LabelEncoder\n",
        "with open(save_path, \"rb\") as file:\n",
        "    loaded_encoder = pickle.load(file)\n",
        "\n",
        "# Test the loaded encoder\n",
        "print(loaded_encoder.classes_)\n"
      ],
      "metadata": {
        "id": "RCY0V6W2XUVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create and fit the label encoder\n",
        "state_encoder = LabelEncoder()\n",
        "labels = [\"Hindi\", \"Telugu\", \"Marathi\", \"Konkani\", \"Bengali\"]\n",
        "state_encoder.fit(labels)\n",
        "\n",
        "# Save the LabelEncoder correctly\n",
        "with open(\"label_encoder.pkl\", \"wb\") as file:\n",
        "    pickle.dump(state_encoder, file)  # ✅ Pass the encoder and the file object\n",
        "\n",
        "# Load the LabelEncoder\n",
        "with open(\"label_encoder.pkl\", \"rb\") as file:\n",
        "    loaded_encoder = pickle.load(file)\n",
        "\n",
        "# Test the loaded encoder\n",
        "print(loaded_encoder.classes_)\n"
      ],
      "metadata": {
        "id": "eYpEwnS8XNkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# 1️⃣ Load Data from CSV\n",
        "# ==============================\n",
        "csv_file_path = \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/merged_data.csv\"  # Update with your file path\n",
        "df = pd.read_csv(csv_file_path)\n",
        "print(df.columns)\n",
        "\n",
        "# ==============================\n",
        "# 2️⃣ Prepare Data (Separate Features & Labels)\n",
        "# ==============================\n",
        "X = df.drop(columns=['id', 'filename', 'file_url', 'state', 'gender', 'pincode', 'district',\n",
        "       'stayYears', 'assertLanguage', 'languagesSpoken'])  # Features\n",
        "y = df['state']  # Target variable (predicting state)\n",
        "\n",
        "# Encode labels (convert state names to numbers)\n",
        "state_encoder = LabelEncoder()\n",
        "y_encoded = state_encoder.fit_transform(y)\n",
        "\n",
        "# Split data into train & test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Set n_neighbors to 1 since you have only 2 samples in the minority class\n",
        "sm = SMOTE(k_neighbors=1)\n",
        "\n",
        "# Apply SMOTE\n",
        "X_sm_train, y_sm_train = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f'''Shape of X before SMOTE: {X_train.shape}\n",
        "Shape of X after SMOTE: {X_sm_train.shape}''')\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_sm_train_scaled = scaler.fit_transform(X_sm_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id4JQgppUtJU",
        "outputId": "8cded287-04f7-4fc5-cb76-48b5cedfd5bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'filename', 'file_url', 'state', 'gender', 'pincode', 'district',\n",
            "       'stayYears', 'assertLanguage', 'languagesSpoken', 'feature_0',\n",
            "       'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5',\n",
            "       'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10',\n",
            "       'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15',\n",
            "       'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20',\n",
            "       'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25',\n",
            "       'feature_26', 'feature_27', 'feature_28', 'feature_29', 'feature_30',\n",
            "       'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_35',\n",
            "       'feature_36', 'feature_37'],\n",
            "      dtype='object')\n",
            "Shape of X before SMOTE: (59187, 38)\n",
            "Shape of X after SMOTE: (152999, 38)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for training the model for predicting states\n"
      ],
      "metadata": {
        "id": "BIuhfjQdSRoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Reshape for LSTM (samples, time steps, features)\n",
        "X_train_reshaped = X_sm_train_scaled.reshape(X_sm_train_scaled.shape[0], 1, X_sm_train_scaled.shape[1])\n",
        "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train_categorical = to_categorical(y_sm_train)\n",
        "y_test_categorical = to_categorical(y_test)\n",
        "\n",
        "# ==============================\n",
        "# 3️⃣ Build BiLSTM Model\n",
        "# ==============================\n",
        "model = Sequential([\n",
        "    Input(shape=(1, X_sm_train_scaled.shape[1])),  # Corrected shape to use shape[1]\n",
        "    Bidirectional(LSTM(256, return_sequences=True)),\n",
        "    Dropout(0.3),\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),\n",
        "    Dropout(0.3),\n",
        "    Bidirectional(LSTM(64, return_sequences=False)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(len(state_encoder.classes_), activation='softmax')  # Number of classes in y\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=10,         # Number of epochs to wait before stopping if no improvement\n",
        "    restore_best_weights=True  # Restore the model weights from the epoch with the best validation loss\n",
        ")\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(\n",
        "    X_train_reshaped, y_train_categorical,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_reshaped, y_test_categorical),\n",
        "    callbacks=[early_stopping]  # Add the EarlyStopping callback\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/my_trained_model.h5')\n",
        "\n",
        "# ==============================\n",
        "# 5️⃣ Evaluate Model\n",
        "# ==============================\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test_categorical)\n",
        "print(f\"BiLSTM Model Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "zPLrIyO2MHdW",
        "outputId": "e24fbefa-6e49-45c5-b372-e85b91f75292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6b2dcc9e4e6f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ==============================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcsv_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/merged_data.csv\"\u001b[0m  \u001b[0;31m# Update with your file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/my_trained_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuOnNK0rTJOo",
        "outputId": "63b29c20-6a40-4352-f406-1333de005e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for predicting the states of new audios"
      ],
      "metadata": {
        "id": "rZHdaw9uSfa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==============================\n",
        "# 1️⃣ Load Data from CSV\n",
        "# ==============================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# ==============================\n",
        "# 1️⃣ Load the Saved Model\n",
        "# ==============================\n",
        "model = load_model('/content/drive/MyDrive/my_trained_model.h5')\n",
        "\n",
        "# ==============================\n",
        "# 2️⃣ Load and Preprocess the New Dataset\n",
        "# ==============================\n",
        "# Load the new dataset\n",
        "new_csv_file_path = \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/test_audio_final.csv\"  # Update with your file path\n",
        "new_df = pd.read_csv(new_csv_file_path)\n",
        "\n",
        "# Ensure the new dataset has the same columns as the training data\n",
        "# Drop the same columns as during training\n",
        "X_new = new_df.drop(columns=['id', 'filename', 'file_url', 'state', 'gender', 'pincode', 'district',\n",
        "                            'stayYears', 'assertLanguage', 'languagesSpoken'])\n",
        "\n",
        "# Normalize the new data using the same scaler as during training\n",
        "# (Assuming you saved the scaler during training; otherwise, refit it)\n",
        "scaler = StandardScaler()\n",
        "X_new = scaler.fit_transform(X_new)  # Use the same scaler as during training\n",
        "\n",
        "# Reshape for LSTM (samples, time steps, features)\n",
        "X_new = X_new.reshape(X_new.shape[0], 1, X_new.shape[1])\n",
        "\n",
        "# ==============================\n",
        "# 3️⃣ Make Predictions\n",
        "# ==============================\n",
        "# Predict on the new data\n",
        "predictions = model.predict(X_new)\n",
        "\n",
        "# Convert predictions from probabilities to class labels\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# ==============================\n",
        "# 4️⃣ Decode Predictions\n",
        "# ==============================\n",
        "# If the target variable was label-encoded during training, decode the predictions\n",
        "# Load or recreate the LabelEncoder used during training\n",
        "state_encoder = LabelEncoder()\n",
        "state_encoder.fit(df['state'])  # Assuming `df` is the original training data\n",
        "\n",
        "# Decode the predicted classes back to state names\n",
        "predicted_states = state_encoder.inverse_transform(predicted_classes)\n",
        "\n",
        "# Add the predicted states to the new dataset\n",
        "new_df['predicted_state'] = predicted_states\n",
        "\n",
        "# ==============================\n",
        "# 5️⃣ Save or Display Results\n",
        "# ==============================\n",
        "# Save the new dataset with predictions to a CSV file\n",
        "new_df.to_csv('new_dataset_with_predictions.csv', index=False)\n",
        "\n",
        "# Display the first few rows with predictions\n",
        "print(new_df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkFFNm-pMTt6",
        "outputId": "6ab23629-a5e3-48f3-a3e0-5297985e4c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 476ms/step\n",
            "        id                                           filename  \\\n",
            "0  7563707  IISc_VaaniProject_M_BR_Araria_Nita36727_144641...   \n",
            "1  7563721  IISc_VaaniProject_M_BR_Araria_71981266_1247070...   \n",
            "2  7563709  IISc_VaaniProject_M_BR_Araria_Nita36727_144844...   \n",
            "3  7563714  IISc_VaaniProject_M_BR_Araria_Nita36727_144641...   \n",
            "4  7563713  IISc_VaaniProject_M_BR_Araria_Rahu87667_001310...   \n",
            "\n",
            "                                            file_url  state  gender  pincode  \\\n",
            "0  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...  Bihar    male   854325   \n",
            "1  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...  Bihar  female   854328   \n",
            "2  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...  Bihar    male   854325   \n",
            "3  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...  Bihar    male   854325   \n",
            "4  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...  Bihar    male   854328   \n",
            "\n",
            "  district stayYears assertLanguage languagesSpoken  ...  feature_29  \\\n",
            "0   Araria        21          HINDI       ['Hindi']  ...   24.213826   \n",
            "1   Araria        39          HINDI       ['Hindi']  ...   21.145171   \n",
            "2   Araria        21          HINDI       ['Hindi']  ...   25.709413   \n",
            "3   Araria        21          HINDI       ['Hindi']  ...   24.790419   \n",
            "4   Araria        23          HINDI       ['Hindi']  ...   21.786797   \n",
            "\n",
            "   feature_30  feature_31  feature_32  feature_33  feature_34  feature_35  \\\n",
            "0   29.381877   14.743478    0.033548    0.011172   -0.025681   -0.073708   \n",
            "1   23.260481   31.949563    0.014118   -0.005542    0.056249   -0.050925   \n",
            "2   35.111273   14.684528    0.025488    0.024609    0.015288   -0.115441   \n",
            "3   33.726518   14.984811   -0.015004   -0.089572   -0.149736   -0.045910   \n",
            "4   26.326641   16.187632    0.004982   -0.054480   -0.004590    0.063494   \n",
            "\n",
            "   feature_36  feature_37  predicted_state  \n",
            "0   -0.039746    0.011990        Jharkhand  \n",
            "1    0.005657    0.001793     Chhattisgarh  \n",
            "2   -0.032343    0.001734      Maharashtra  \n",
            "3   -0.001094   -0.050903        Telangana  \n",
            "4   -0.009028   -0.021561        Jharkhand  \n",
            "\n",
            "[5 rows x 49 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zJpPmZB3TQiK",
        "outputId": "0e44770b-a997-423f-c52d-34fccf59c59d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id                                           filename  \\\n",
              "0   7563707  IISc_VaaniProject_M_BR_Araria_Nita36727_144641...   \n",
              "1   7563721  IISc_VaaniProject_M_BR_Araria_71981266_1247070...   \n",
              "2   7563709  IISc_VaaniProject_M_BR_Araria_Nita36727_144844...   \n",
              "3   7563714  IISc_VaaniProject_M_BR_Araria_Nita36727_144641...   \n",
              "4   7563713  IISc_VaaniProject_M_BR_Araria_Rahu87667_001310...   \n",
              "5   7563717  IISc_VaaniProject_M_BR_Araria_Rahu87667_001310...   \n",
              "6   7584792  IISc_VaaniProject_M_RJ_Nagaur_Balv21710_072937...   \n",
              "7   7584876  IISc_VaaniProject_M_RJ_Nagaur_Arju18568_035217...   \n",
              "8   7584805  IISc_VaaniProject_M_RJ_Nagaur_Balv21710_072715...   \n",
              "9   7584829  IISc_VaaniProject_M_RJ_Nagaur_Vije16053_111444...   \n",
              "10  7584853  IISc_VaaniProject_M_RJ_Nagaur_Arju18568_040345...   \n",
              "11  8211345  IISc_VaaniProject_M_BR_Araria_Farh09029_162044...   \n",
              "12  8211324  IISc_VaaniProject_M_BR_Araria_Ritu11232_083515...   \n",
              "13  8211352  IISc_VaaniProject_M_BR_Araria_Meen24716_192307...   \n",
              "14  8211323  IISc_VaaniProject_M_BR_Araria_Ritu11232_082649...   \n",
              "15  8452228  IISc_VaaniProject_M_BR_Araria_Nidh75645_025838...   \n",
              "16  8452221  IISc_VaaniProject_M_BR_Araria_Nidh75645_081831...   \n",
              "17  8452212  IISc_VaaniProject_M_BR_Araria_Nidh75645_020823...   \n",
              "18  8452252  IISc_VaaniProject_M_BR_Araria_60633421_1325210...   \n",
              "19  8452260  IISc_VaaniProject_M_BR_Araria_Nidh75645_020734...   \n",
              "20  8722054  IISc_VaaniProject_M_GA_NorthSouthGoa_Sabr72061...   \n",
              "21  8722050  IISc_VaaniProject_M_GA_NorthSouthGoa_Anil59585...   \n",
              "22  8731260  IISc_VaaniProject_M_GA_NorthSouthGoa_Praj98887...   \n",
              "23  8731203  IISc_VaaniProject_M_GA_NorthSouthGoa_Vina68997...   \n",
              "24  8902498  IISc_VaaniProject_M_JH_Jamtara_Akas11827_11033...   \n",
              "25  8902501  IISc_VaaniProject_M_JH_Jamtara_Akas11827_11005...   \n",
              "26  8902506  IISc_VaaniProject_M_JH_Jamtara_Akas11827_11153...   \n",
              "27  8902513  IISc_VaaniProject_M_JH_Jamtara_Akas11827_10492...   \n",
              "28  8902546  IISc_VaaniProject_M_JH_Jamtara_Moni44669_08330...   \n",
              "29  8902562  IISc_VaaniProject_M_JH_Jamtara_Moni44669_09120...   \n",
              "30  2020253  IISc_VaaniProject_S_Uttarpradesh_Hamirpur_1421...   \n",
              "31  2023315  IISc_VaaniProject_S_Uttarpradesh_Hamirpur_1463...   \n",
              "32  2023770  IISc_VaaniProject_S_Uttarpradesh_Hamirpur_1373...   \n",
              "33  2025055  IISc_VaaniProject_S_Uttarpradesh_Hamirpur_1464...   \n",
              "34  2044205  IISc_VaaniProject_S_Uttarpradesh_Hamirpur_1312...   \n",
              "35  2042854  IISc_VaaniProject_S_Uttarpradesh_Hamirpur_1288...   \n",
              "36  2045302  IISc_VaaniProject_S_Uttarpradesh_Hamirpur_1392...   \n",
              "37  2045301  IISc_VaaniProject_S_Uttarpradesh_Hamirpur_1392...   \n",
              "38  2048252  IISc_VaaniProject_S_Uttarpradesh_Hamirpur_1309...   \n",
              "39  7563707  IISc_VaaniProject_M_BR_Araria_Nita36727_144641...   \n",
              "40  7563721  IISc_VaaniProject_M_BR_Araria_71981266_1247070...   \n",
              "41  7563709  IISc_VaaniProject_M_BR_Araria_Nita36727_144844...   \n",
              "42  7563714  IISc_VaaniProject_M_BR_Araria_Nita36727_144641...   \n",
              "43  7563713  IISc_VaaniProject_M_BR_Araria_Rahu87667_001310...   \n",
              "44  7563717  IISc_VaaniProject_M_BR_Araria_Rahu87667_001310...   \n",
              "\n",
              "                                             file_url         state  gender  \\\n",
              "0   https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar    male   \n",
              "1   https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar  female   \n",
              "2   https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar    male   \n",
              "3   https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar    male   \n",
              "4   https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar    male   \n",
              "5   https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar    male   \n",
              "6   https://vaani.iisc.ac.in//Audios/Nagaur/IISc_V...     Rajasthan    male   \n",
              "7   https://vaani.iisc.ac.in//Audios/Nagaur/IISc_V...     Rajasthan    male   \n",
              "8   https://vaani.iisc.ac.in//Audios/Nagaur/IISc_V...     Rajasthan    male   \n",
              "9   https://vaani.iisc.ac.in//Audios/Nagaur/IISc_V...     Rajasthan    male   \n",
              "10  https://vaani.iisc.ac.in//Audios/Nagaur/IISc_V...     Rajasthan    male   \n",
              "11  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar  female   \n",
              "12  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar  female   \n",
              "13  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar  female   \n",
              "14  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar  female   \n",
              "15  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar  female   \n",
              "16  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar  female   \n",
              "17  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar  female   \n",
              "18  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar  female   \n",
              "19  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar  female   \n",
              "20  https://vaani.iisc.ac.in//Audios/NorthSouthGoa...           Goa  female   \n",
              "21  https://vaani.iisc.ac.in//Audios/NorthSouthGoa...           Goa    male   \n",
              "22  https://vaani.iisc.ac.in//Audios/NorthSouthGoa...           Goa  female   \n",
              "23  https://vaani.iisc.ac.in//Audios/NorthSouthGoa...           Goa  female   \n",
              "24  https://vaani.iisc.ac.in//Audios/Jamtara/IISc_...     Jharkhand    male   \n",
              "25  https://vaani.iisc.ac.in//Audios/Jamtara/IISc_...     Jharkhand    male   \n",
              "26  https://vaani.iisc.ac.in//Audios/Jamtara/IISc_...     Jharkhand    male   \n",
              "27  https://vaani.iisc.ac.in//Audios/Jamtara/IISc_...     Jharkhand    male   \n",
              "28  https://vaani.iisc.ac.in//Audios/Jamtara/IISc_...     Jharkhand  female   \n",
              "29  https://vaani.iisc.ac.in//Audios/Jamtara/IISc_...     Jharkhand  female   \n",
              "30  https://vaani.iisc.ac.in/Audios/Hamirpur/IISc_...  UttarPradesh    male   \n",
              "31  https://vaani.iisc.ac.in/Audios/Hamirpur/IISc_...  UttarPradesh    male   \n",
              "32  https://vaani.iisc.ac.in/Audios/Hamirpur/IISc_...  UttarPradesh  female   \n",
              "33  https://vaani.iisc.ac.in/Audios/Hamirpur/IISc_...  UttarPradesh    male   \n",
              "34  https://vaani.iisc.ac.in/Audios/Hamirpur/IISc_...  UttarPradesh    male   \n",
              "35  https://vaani.iisc.ac.in/Audios/Hamirpur/IISc_...  UttarPradesh  female   \n",
              "36  https://vaani.iisc.ac.in/Audios/Hamirpur/IISc_...  UttarPradesh  female   \n",
              "37  https://vaani.iisc.ac.in/Audios/Hamirpur/IISc_...  UttarPradesh  female   \n",
              "38  https://vaani.iisc.ac.in/Audios/Hamirpur/IISc_...  UttarPradesh    male   \n",
              "39  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar    male   \n",
              "40  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar  female   \n",
              "41  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar    male   \n",
              "42  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar    male   \n",
              "43  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar    male   \n",
              "44  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...         Bihar    male   \n",
              "\n",
              "    pincode       district     stayYears assertLanguage  \\\n",
              "0    854325         Araria            21          HINDI   \n",
              "1    854328         Araria            39          HINDI   \n",
              "2    854325         Araria            21          HINDI   \n",
              "3    854325         Araria            21          HINDI   \n",
              "4    854328         Araria            23          HINDI   \n",
              "5    854328         Araria            23          HINDI   \n",
              "6    341023         Nagaur            20        MARWARI   \n",
              "7    341024         Nagaur            27     RAJASTHANI   \n",
              "8    341023         Nagaur            20        MARWARI   \n",
              "9    341024         Nagaur            34        MARWARI   \n",
              "10   341024         Nagaur            27     RAJASTHANI   \n",
              "11   854328         Araria            27          HINDI   \n",
              "12   854318         Araria            15          HINDI   \n",
              "13   854325         Araria             7          HINDI   \n",
              "14   854318         Araria            15          HINDI   \n",
              "15   854316         Araria            13          HINDI   \n",
              "16   854316         Araria            13          HINDI   \n",
              "17   854316         Araria            13          HINDI   \n",
              "18   854316         Araria            35          HINDI   \n",
              "19   854316         Araria            13          HINDI   \n",
              "20   403004  NorthSouthGoa            20        MARATHI   \n",
              "21   403002  NorthSouthGoa            24          HINDI   \n",
              "22   403105  NorthSouthGoa            20        KONKANI   \n",
              "23   403105  NorthSouthGoa            20        KONKANI   \n",
              "24   815355        Jamtara            21          HINDI   \n",
              "25   815355        Jamtara            21          HINDI   \n",
              "26   815355        Jamtara            21          HINDI   \n",
              "27   815355        Jamtara            21          HINDI   \n",
              "28   815354        Jamtara            13          HINDI   \n",
              "29   815354        Jamtara            13          HINDI   \n",
              "30   210502       Hamirpur  Hamirpur(21)          HINDI   \n",
              "31   210507       Hamirpur  Hamirpur(40)          HINDI   \n",
              "32   176043       Hamirpur  Hamirpur(30)          HINDI   \n",
              "33   177029       Hamirpur  Hamirpur(40)          HINDI   \n",
              "34   210341       Hamirpur  Hamirpur(27)          HINDI   \n",
              "35   174305       Hamirpur  Hamirpur(22)          HINDI   \n",
              "36   177030       Hamirpur  Hamirpur(27)          HINDI   \n",
              "37   177030       Hamirpur  Hamirpur(27)          HINDI   \n",
              "38   210341       Hamirpur  Hamirpur(45)          HINDI   \n",
              "39   854325         Araria            21          HINDI   \n",
              "40   854328         Araria            39          HINDI   \n",
              "41   854325         Araria            21          HINDI   \n",
              "42   854325         Araria            21          HINDI   \n",
              "43   854328         Araria            23          HINDI   \n",
              "44   854328         Araria            23          HINDI   \n",
              "\n",
              "                    languagesSpoken  ...  feature_29  feature_30  feature_31  \\\n",
              "0                         ['Hindi']  ...   24.213826   29.381877   14.743478   \n",
              "1                         ['Hindi']  ...   21.145171   23.260481   31.949563   \n",
              "2                         ['Hindi']  ...   25.709413   35.111273   14.684528   \n",
              "3                         ['Hindi']  ...   24.790419   33.726518   14.984811   \n",
              "4                         ['Hindi']  ...   21.786797   26.326641   16.187632   \n",
              "5                         ['Hindi']  ...   19.801884   23.499042   15.239035   \n",
              "6            ['Marwari', 'Marwadi']  ...   19.329682   17.749703   15.808508   \n",
              "7           ['Rajasthani', 'Hindi']  ...   17.555888   15.870106   14.698688   \n",
              "8            ['Marwari', 'Marwadi']  ...   20.373575   23.976266   20.213988   \n",
              "9   ['Marwari', 'Marwadi', 'Hindi']  ...   21.599105   22.877773   28.405642   \n",
              "10          ['Rajasthani', 'Hindi']  ...   19.840724   19.056869   14.835862   \n",
              "11                        ['Hindi']  ...   16.826299   14.294676   22.149311   \n",
              "12                        ['Hindi']  ...   19.684549   20.359091   19.729919   \n",
              "13                        ['Hindi']  ...   17.879030   19.918978   18.107603   \n",
              "14                        ['Hindi']  ...   21.817854   18.206683   18.091582   \n",
              "15                        ['Hindi']  ...   22.006826   22.125534   28.394295   \n",
              "16                        ['Hindi']  ...   19.344942   20.293939   27.459724   \n",
              "17                        ['Hindi']  ...   22.247654   22.130522   21.182173   \n",
              "18                        ['Hindi']  ...   26.676153   28.103054   28.713947   \n",
              "19                        ['Hindi']  ...   22.872500   23.139681   26.641755   \n",
              "20                      ['Marathi']  ...   16.680171   16.800463   16.467596   \n",
              "21                        ['Hindi']  ...   17.516696   16.027221   16.196954   \n",
              "22                      ['Marathi']  ...   21.693933   25.092021   17.620162   \n",
              "23                      ['Marathi']  ...   22.061460   24.732733   34.868406   \n",
              "24                        ['Hindi']  ...   21.240514   21.517392   20.198155   \n",
              "25                        ['Hindi']  ...   21.090096   21.503910   19.982245   \n",
              "26                        ['Hindi']  ...   18.993091   22.431204   21.796884   \n",
              "27                        ['Hindi']  ...   19.517374   21.356589   23.658518   \n",
              "28                        ['Hindi']  ...   22.737129   24.205310   16.363754   \n",
              "29                        ['Hindi']  ...   20.107297   22.062982   18.720584   \n",
              "30                        ['Hindi']  ...   21.761462   18.297386   18.082116   \n",
              "31                        ['Hindi']  ...   22.392923   22.584244   16.426298   \n",
              "32                        ['Hindi']  ...   20.176789   28.414108   17.073517   \n",
              "33                        ['Hindi']  ...   19.274688   19.594370   31.871490   \n",
              "34                        ['Hindi']  ...   18.085065   17.635143   18.427341   \n",
              "35                        ['Hindi']  ...   21.792511   22.876662   20.172045   \n",
              "36                        ['Hindi']  ...   22.658528   22.944902   19.639080   \n",
              "37                        ['Hindi']  ...   24.613697   22.486710   18.036577   \n",
              "38                        ['Hindi']  ...   17.528451   17.183736   16.128407   \n",
              "39                        ['Hindi']  ...   24.213826   29.381877   14.743478   \n",
              "40                        ['Hindi']  ...   21.145171   23.260481   31.949563   \n",
              "41                        ['Hindi']  ...   25.709413   35.111273   14.684528   \n",
              "42                        ['Hindi']  ...   24.790419   33.726518   14.984811   \n",
              "43                        ['Hindi']  ...   21.786797   26.326641   16.187632   \n",
              "44                        ['Hindi']  ...   19.801884   23.499042   15.239035   \n",
              "\n",
              "    feature_32  feature_33  feature_34  feature_35  feature_36  feature_37  \\\n",
              "0     0.033548    0.011172   -0.025681   -0.073708   -0.039746    0.011990   \n",
              "1     0.014118   -0.005542    0.056249   -0.050925    0.005657    0.001793   \n",
              "2     0.025488    0.024609    0.015288   -0.115441   -0.032343    0.001734   \n",
              "3    -0.015004   -0.089572   -0.149736   -0.045910   -0.001094   -0.050903   \n",
              "4     0.004982   -0.054480   -0.004590    0.063494   -0.009028   -0.021561   \n",
              "5    -0.014291    0.012650   -0.080028    0.104683    0.014374   -0.000841   \n",
              "6     0.141660    0.000532    0.288419   -0.234678    0.096259    0.012698   \n",
              "7     0.049085   -0.039405    0.059207   -0.173001    0.038262    0.030731   \n",
              "8     0.158566    0.113788    0.307405   -0.165980    0.105910   -0.032990   \n",
              "9     0.007638    0.035126   -0.009001    0.047112    0.025167    0.013869   \n",
              "10    0.007583   -0.114068    0.004512   -0.224041    0.041272    0.068698   \n",
              "11    0.057983    0.021218    0.020104   -0.118996   -0.017182   -0.005457   \n",
              "12   -0.073961   -0.096637   -0.224027    0.032291    0.073439   -0.049265   \n",
              "13    0.012855    0.030953    0.059179   -0.081614    0.024285   -0.010444   \n",
              "14    0.209405    0.105128   -0.032243   -0.340099   -0.109541   -0.053401   \n",
              "15   -0.023083   -0.061232   -0.042168    0.078160   -0.012109    0.007823   \n",
              "16    0.028071    0.025662   -0.106937   -0.046950    0.028308    0.017476   \n",
              "17    0.012816   -0.007296   -0.058542   -0.005196    0.006913    0.003706   \n",
              "18   -0.008047    0.027965    0.060195    0.031309   -0.013097   -0.016487   \n",
              "19   -0.031102    0.000870   -0.017570    0.074675   -0.012391    0.012062   \n",
              "20   -0.005570   -0.019252    0.076206   -0.035298    0.002397    0.007134   \n",
              "21   -0.027349   -0.009023   -0.099184    0.017771    0.000413    0.007045   \n",
              "22    0.070390   -0.027319   -0.042889   -0.034537    0.007391    0.006658   \n",
              "23   -0.004719   -0.013178   -0.026895    0.013511   -0.005459   -0.003941   \n",
              "24    0.003010   -0.009109   -0.032372    0.078265   -0.018999    0.017004   \n",
              "25    0.033440   -0.027626   -0.066554    0.024623    0.000802    0.023067   \n",
              "26   -0.017036    0.003875   -0.016402    0.151669   -0.020153   -0.007222   \n",
              "27   -0.023965   -0.009520   -0.012426    0.047171   -0.010807   -0.001349   \n",
              "28    0.005788    0.024982    0.091583   -0.002971    0.015759   -0.022182   \n",
              "29    0.017447    0.036438    0.025848    0.035064    0.011125   -0.010919   \n",
              "30    0.053892   -0.000788   -0.098290   -0.134976   -0.039377   -0.029764   \n",
              "31   -0.057120    0.015544    0.085747    0.086586   -0.037201   -0.034397   \n",
              "32   -0.016806   -0.015444    0.026867   -0.078157    0.009037    0.008960   \n",
              "33   -0.122455    0.052329    0.039435   -0.225275    0.009150   -0.073878   \n",
              "34    0.053605   -0.002327   -0.026504    0.110849   -0.011136   -0.014266   \n",
              "35   -0.013297    0.022767    0.084327    0.084536   -0.001824   -0.023511   \n",
              "36   -0.072920    0.024703    0.007112   -0.122862    0.017660   -0.024392   \n",
              "37   -0.051546   -0.032764    0.079223   -0.177445   -0.011134   -0.054092   \n",
              "38   -0.002045   -0.009768    0.068103   -0.117610   -0.000703   -0.023669   \n",
              "39    0.033548    0.011172   -0.025681   -0.073708   -0.039746    0.011990   \n",
              "40    0.014118   -0.005542    0.056249   -0.050925    0.005657    0.001793   \n",
              "41    0.025488    0.024609    0.015288   -0.115441   -0.032343    0.001734   \n",
              "42   -0.015004   -0.089572   -0.149736   -0.045910   -0.001094   -0.050903   \n",
              "43    0.004982   -0.054480   -0.004590    0.063494   -0.009028   -0.021561   \n",
              "44   -0.014291    0.012650   -0.080028    0.104683    0.014374   -0.000841   \n",
              "\n",
              "    predicted_state  \n",
              "0         Jharkhand  \n",
              "1      Chhattisgarh  \n",
              "2       Maharashtra  \n",
              "3         Telangana  \n",
              "4         Jharkhand  \n",
              "5         Telangana  \n",
              "6         Rajasthan  \n",
              "7        WestBengal  \n",
              "8         Rajasthan  \n",
              "9         Rajasthan  \n",
              "10        Rajasthan  \n",
              "11            Bihar  \n",
              "12            Bihar  \n",
              "13        Jharkhand  \n",
              "14            Bihar  \n",
              "15            Bihar  \n",
              "16            Bihar  \n",
              "17            Bihar  \n",
              "18        Karnataka  \n",
              "19        Telangana  \n",
              "20              Goa  \n",
              "21              Goa  \n",
              "22              Goa  \n",
              "23        Karnataka  \n",
              "24     Chhattisgarh  \n",
              "25     Chhattisgarh  \n",
              "26            Bihar  \n",
              "27    AndhraPradesh  \n",
              "28        Jharkhand  \n",
              "29        Jharkhand  \n",
              "30        Jharkhand  \n",
              "31              Goa  \n",
              "32     Chhattisgarh  \n",
              "33        Rajasthan  \n",
              "34        Rajasthan  \n",
              "35       WestBengal  \n",
              "36            Bihar  \n",
              "37            Bihar  \n",
              "38     UttarPradesh  \n",
              "39        Jharkhand  \n",
              "40     Chhattisgarh  \n",
              "41      Maharashtra  \n",
              "42        Telangana  \n",
              "43        Jharkhand  \n",
              "44        Telangana  \n",
              "\n",
              "[45 rows x 49 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4803805f-8b10-41ee-908c-d86ce67bc617\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>filename</th>\n",
              "      <th>file_url</th>\n",
              "      <th>state</th>\n",
              "      <th>gender</th>\n",
              "      <th>pincode</th>\n",
              "      <th>district</th>\n",
              "      <th>stayYears</th>\n",
              "      <th>assertLanguage</th>\n",
              "      <th>languagesSpoken</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_29</th>\n",
              "      <th>feature_30</th>\n",
              "      <th>feature_31</th>\n",
              "      <th>feature_32</th>\n",
              "      <th>feature_33</th>\n",
              "      <th>feature_34</th>\n",
              "      <th>feature_35</th>\n",
              "      <th>feature_36</th>\n",
              "      <th>feature_37</th>\n",
              "      <th>predicted_state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7563707</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_Nita36727_144641...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>male</td>\n",
              "      <td>854325</td>\n",
              "      <td>Araria</td>\n",
              "      <td>21</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>24.213826</td>\n",
              "      <td>29.381877</td>\n",
              "      <td>14.743478</td>\n",
              "      <td>0.033548</td>\n",
              "      <td>0.011172</td>\n",
              "      <td>-0.025681</td>\n",
              "      <td>-0.073708</td>\n",
              "      <td>-0.039746</td>\n",
              "      <td>0.011990</td>\n",
              "      <td>Jharkhand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7563721</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_71981266_1247070...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>female</td>\n",
              "      <td>854328</td>\n",
              "      <td>Araria</td>\n",
              "      <td>39</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>21.145171</td>\n",
              "      <td>23.260481</td>\n",
              "      <td>31.949563</td>\n",
              "      <td>0.014118</td>\n",
              "      <td>-0.005542</td>\n",
              "      <td>0.056249</td>\n",
              "      <td>-0.050925</td>\n",
              "      <td>0.005657</td>\n",
              "      <td>0.001793</td>\n",
              "      <td>Chhattisgarh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7563709</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_Nita36727_144844...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>male</td>\n",
              "      <td>854325</td>\n",
              "      <td>Araria</td>\n",
              "      <td>21</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>25.709413</td>\n",
              "      <td>35.111273</td>\n",
              "      <td>14.684528</td>\n",
              "      <td>0.025488</td>\n",
              "      <td>0.024609</td>\n",
              "      <td>0.015288</td>\n",
              "      <td>-0.115441</td>\n",
              "      <td>-0.032343</td>\n",
              "      <td>0.001734</td>\n",
              "      <td>Maharashtra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7563714</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_Nita36727_144641...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>male</td>\n",
              "      <td>854325</td>\n",
              "      <td>Araria</td>\n",
              "      <td>21</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>24.790419</td>\n",
              "      <td>33.726518</td>\n",
              "      <td>14.984811</td>\n",
              "      <td>-0.015004</td>\n",
              "      <td>-0.089572</td>\n",
              "      <td>-0.149736</td>\n",
              "      <td>-0.045910</td>\n",
              "      <td>-0.001094</td>\n",
              "      <td>-0.050903</td>\n",
              "      <td>Telangana</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7563713</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_Rahu87667_001310...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>male</td>\n",
              "      <td>854328</td>\n",
              "      <td>Araria</td>\n",
              "      <td>23</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>21.786797</td>\n",
              "      <td>26.326641</td>\n",
              "      <td>16.187632</td>\n",
              "      <td>0.004982</td>\n",
              "      <td>-0.054480</td>\n",
              "      <td>-0.004590</td>\n",
              "      <td>0.063494</td>\n",
              "      <td>-0.009028</td>\n",
              "      <td>-0.021561</td>\n",
              "      <td>Jharkhand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>7563717</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_Rahu87667_001310...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>male</td>\n",
              "      <td>854328</td>\n",
              "      <td>Araria</td>\n",
              "      <td>23</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>19.801884</td>\n",
              "      <td>23.499042</td>\n",
              "      <td>15.239035</td>\n",
              "      <td>-0.014291</td>\n",
              "      <td>0.012650</td>\n",
              "      <td>-0.080028</td>\n",
              "      <td>0.104683</td>\n",
              "      <td>0.014374</td>\n",
              "      <td>-0.000841</td>\n",
              "      <td>Telangana</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7584792</td>\n",
              "      <td>IISc_VaaniProject_M_RJ_Nagaur_Balv21710_072937...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Nagaur/IISc_V...</td>\n",
              "      <td>Rajasthan</td>\n",
              "      <td>male</td>\n",
              "      <td>341023</td>\n",
              "      <td>Nagaur</td>\n",
              "      <td>20</td>\n",
              "      <td>MARWARI</td>\n",
              "      <td>['Marwari', 'Marwadi']</td>\n",
              "      <td>...</td>\n",
              "      <td>19.329682</td>\n",
              "      <td>17.749703</td>\n",
              "      <td>15.808508</td>\n",
              "      <td>0.141660</td>\n",
              "      <td>0.000532</td>\n",
              "      <td>0.288419</td>\n",
              "      <td>-0.234678</td>\n",
              "      <td>0.096259</td>\n",
              "      <td>0.012698</td>\n",
              "      <td>Rajasthan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7584876</td>\n",
              "      <td>IISc_VaaniProject_M_RJ_Nagaur_Arju18568_035217...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Nagaur/IISc_V...</td>\n",
              "      <td>Rajasthan</td>\n",
              "      <td>male</td>\n",
              "      <td>341024</td>\n",
              "      <td>Nagaur</td>\n",
              "      <td>27</td>\n",
              "      <td>RAJASTHANI</td>\n",
              "      <td>['Rajasthani', 'Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>17.555888</td>\n",
              "      <td>15.870106</td>\n",
              "      <td>14.698688</td>\n",
              "      <td>0.049085</td>\n",
              "      <td>-0.039405</td>\n",
              "      <td>0.059207</td>\n",
              "      <td>-0.173001</td>\n",
              "      <td>0.038262</td>\n",
              "      <td>0.030731</td>\n",
              "      <td>WestBengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7584805</td>\n",
              "      <td>IISc_VaaniProject_M_RJ_Nagaur_Balv21710_072715...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Nagaur/IISc_V...</td>\n",
              "      <td>Rajasthan</td>\n",
              "      <td>male</td>\n",
              "      <td>341023</td>\n",
              "      <td>Nagaur</td>\n",
              "      <td>20</td>\n",
              "      <td>MARWARI</td>\n",
              "      <td>['Marwari', 'Marwadi']</td>\n",
              "      <td>...</td>\n",
              "      <td>20.373575</td>\n",
              "      <td>23.976266</td>\n",
              "      <td>20.213988</td>\n",
              "      <td>0.158566</td>\n",
              "      <td>0.113788</td>\n",
              "      <td>0.307405</td>\n",
              "      <td>-0.165980</td>\n",
              "      <td>0.105910</td>\n",
              "      <td>-0.032990</td>\n",
              "      <td>Rajasthan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7584829</td>\n",
              "      <td>IISc_VaaniProject_M_RJ_Nagaur_Vije16053_111444...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Nagaur/IISc_V...</td>\n",
              "      <td>Rajasthan</td>\n",
              "      <td>male</td>\n",
              "      <td>341024</td>\n",
              "      <td>Nagaur</td>\n",
              "      <td>34</td>\n",
              "      <td>MARWARI</td>\n",
              "      <td>['Marwari', 'Marwadi', 'Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>21.599105</td>\n",
              "      <td>22.877773</td>\n",
              "      <td>28.405642</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.035126</td>\n",
              "      <td>-0.009001</td>\n",
              "      <td>0.047112</td>\n",
              "      <td>0.025167</td>\n",
              "      <td>0.013869</td>\n",
              "      <td>Rajasthan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7584853</td>\n",
              "      <td>IISc_VaaniProject_M_RJ_Nagaur_Arju18568_040345...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Nagaur/IISc_V...</td>\n",
              "      <td>Rajasthan</td>\n",
              "      <td>male</td>\n",
              "      <td>341024</td>\n",
              "      <td>Nagaur</td>\n",
              "      <td>27</td>\n",
              "      <td>RAJASTHANI</td>\n",
              "      <td>['Rajasthani', 'Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>19.840724</td>\n",
              "      <td>19.056869</td>\n",
              "      <td>14.835862</td>\n",
              "      <td>0.007583</td>\n",
              "      <td>-0.114068</td>\n",
              "      <td>0.004512</td>\n",
              "      <td>-0.224041</td>\n",
              "      <td>0.041272</td>\n",
              "      <td>0.068698</td>\n",
              "      <td>Rajasthan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>8211345</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_Farh09029_162044...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>female</td>\n",
              "      <td>854328</td>\n",
              "      <td>Araria</td>\n",
              "      <td>27</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>16.826299</td>\n",
              "      <td>14.294676</td>\n",
              "      <td>22.149311</td>\n",
              "      <td>0.057983</td>\n",
              "      <td>0.021218</td>\n",
              "      <td>0.020104</td>\n",
              "      <td>-0.118996</td>\n",
              "      <td>-0.017182</td>\n",
              "      <td>-0.005457</td>\n",
              "      <td>Bihar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>8211324</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_Ritu11232_083515...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>female</td>\n",
              "      <td>854318</td>\n",
              "      <td>Araria</td>\n",
              "      <td>15</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>19.684549</td>\n",
              "      <td>20.359091</td>\n",
              "      <td>19.729919</td>\n",
              "      <td>-0.073961</td>\n",
              "      <td>-0.096637</td>\n",
              "      <td>-0.224027</td>\n",
              "      <td>0.032291</td>\n",
              "      <td>0.073439</td>\n",
              "      <td>-0.049265</td>\n",
              "      <td>Bihar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>8211352</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_Meen24716_192307...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>female</td>\n",
              "      <td>854325</td>\n",
              "      <td>Araria</td>\n",
              "      <td>7</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>17.879030</td>\n",
              "      <td>19.918978</td>\n",
              "      <td>18.107603</td>\n",
              "      <td>0.012855</td>\n",
              "      <td>0.030953</td>\n",
              "      <td>0.059179</td>\n",
              "      <td>-0.081614</td>\n",
              "      <td>0.024285</td>\n",
              "      <td>-0.010444</td>\n",
              "      <td>Jharkhand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>8211323</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_Ritu11232_082649...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>female</td>\n",
              "      <td>854318</td>\n",
              "      <td>Araria</td>\n",
              "      <td>15</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>21.817854</td>\n",
              "      <td>18.206683</td>\n",
              "      <td>18.091582</td>\n",
              "      <td>0.209405</td>\n",
              "      <td>0.105128</td>\n",
              "      <td>-0.032243</td>\n",
              "      <td>-0.340099</td>\n",
              "      <td>-0.109541</td>\n",
              "      <td>-0.053401</td>\n",
              "      <td>Bihar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>8452228</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_Nidh75645_025838...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>female</td>\n",
              "      <td>854316</td>\n",
              "      <td>Araria</td>\n",
              "      <td>13</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>22.006826</td>\n",
              "      <td>22.125534</td>\n",
              "      <td>28.394295</td>\n",
              "      <td>-0.023083</td>\n",
              "      <td>-0.061232</td>\n",
              "      <td>-0.042168</td>\n",
              "      <td>0.078160</td>\n",
              "      <td>-0.012109</td>\n",
              "      <td>0.007823</td>\n",
              "      <td>Bihar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>8452221</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_Nidh75645_081831...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>female</td>\n",
              "      <td>854316</td>\n",
              "      <td>Araria</td>\n",
              "      <td>13</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>19.344942</td>\n",
              "      <td>20.293939</td>\n",
              "      <td>27.459724</td>\n",
              "      <td>0.028071</td>\n",
              "      <td>0.025662</td>\n",
              "      <td>-0.106937</td>\n",
              "      <td>-0.046950</td>\n",
              "      <td>0.028308</td>\n",
              "      <td>0.017476</td>\n",
              "      <td>Bihar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>8452212</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_Nidh75645_020823...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>female</td>\n",
              "      <td>854316</td>\n",
              "      <td>Araria</td>\n",
              "      <td>13</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>22.247654</td>\n",
              "      <td>22.130522</td>\n",
              "      <td>21.182173</td>\n",
              "      <td>0.012816</td>\n",
              "      <td>-0.007296</td>\n",
              "      <td>-0.058542</td>\n",
              "      <td>-0.005196</td>\n",
              "      <td>0.006913</td>\n",
              "      <td>0.003706</td>\n",
              "      <td>Bihar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>8452252</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_60633421_1325210...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>female</td>\n",
              "      <td>854316</td>\n",
              "      <td>Araria</td>\n",
              "      <td>35</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>26.676153</td>\n",
              "      <td>28.103054</td>\n",
              "      <td>28.713947</td>\n",
              "      <td>-0.008047</td>\n",
              "      <td>0.027965</td>\n",
              "      <td>0.060195</td>\n",
              "      <td>0.031309</td>\n",
              "      <td>-0.013097</td>\n",
              "      <td>-0.016487</td>\n",
              "      <td>Karnataka</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>8452260</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_Nidh75645_020734...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>female</td>\n",
              "      <td>854316</td>\n",
              "      <td>Araria</td>\n",
              "      <td>13</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>22.872500</td>\n",
              "      <td>23.139681</td>\n",
              "      <td>26.641755</td>\n",
              "      <td>-0.031102</td>\n",
              "      <td>0.000870</td>\n",
              "      <td>-0.017570</td>\n",
              "      <td>0.074675</td>\n",
              "      <td>-0.012391</td>\n",
              "      <td>0.012062</td>\n",
              "      <td>Telangana</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>8722054</td>\n",
              "      <td>IISc_VaaniProject_M_GA_NorthSouthGoa_Sabr72061...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/NorthSouthGoa...</td>\n",
              "      <td>Goa</td>\n",
              "      <td>female</td>\n",
              "      <td>403004</td>\n",
              "      <td>NorthSouthGoa</td>\n",
              "      <td>20</td>\n",
              "      <td>MARATHI</td>\n",
              "      <td>['Marathi']</td>\n",
              "      <td>...</td>\n",
              "      <td>16.680171</td>\n",
              "      <td>16.800463</td>\n",
              "      <td>16.467596</td>\n",
              "      <td>-0.005570</td>\n",
              "      <td>-0.019252</td>\n",
              "      <td>0.076206</td>\n",
              "      <td>-0.035298</td>\n",
              "      <td>0.002397</td>\n",
              "      <td>0.007134</td>\n",
              "      <td>Goa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>8722050</td>\n",
              "      <td>IISc_VaaniProject_M_GA_NorthSouthGoa_Anil59585...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/NorthSouthGoa...</td>\n",
              "      <td>Goa</td>\n",
              "      <td>male</td>\n",
              "      <td>403002</td>\n",
              "      <td>NorthSouthGoa</td>\n",
              "      <td>24</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>17.516696</td>\n",
              "      <td>16.027221</td>\n",
              "      <td>16.196954</td>\n",
              "      <td>-0.027349</td>\n",
              "      <td>-0.009023</td>\n",
              "      <td>-0.099184</td>\n",
              "      <td>0.017771</td>\n",
              "      <td>0.000413</td>\n",
              "      <td>0.007045</td>\n",
              "      <td>Goa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>8731260</td>\n",
              "      <td>IISc_VaaniProject_M_GA_NorthSouthGoa_Praj98887...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/NorthSouthGoa...</td>\n",
              "      <td>Goa</td>\n",
              "      <td>female</td>\n",
              "      <td>403105</td>\n",
              "      <td>NorthSouthGoa</td>\n",
              "      <td>20</td>\n",
              "      <td>KONKANI</td>\n",
              "      <td>['Marathi']</td>\n",
              "      <td>...</td>\n",
              "      <td>21.693933</td>\n",
              "      <td>25.092021</td>\n",
              "      <td>17.620162</td>\n",
              "      <td>0.070390</td>\n",
              "      <td>-0.027319</td>\n",
              "      <td>-0.042889</td>\n",
              "      <td>-0.034537</td>\n",
              "      <td>0.007391</td>\n",
              "      <td>0.006658</td>\n",
              "      <td>Goa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>8731203</td>\n",
              "      <td>IISc_VaaniProject_M_GA_NorthSouthGoa_Vina68997...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/NorthSouthGoa...</td>\n",
              "      <td>Goa</td>\n",
              "      <td>female</td>\n",
              "      <td>403105</td>\n",
              "      <td>NorthSouthGoa</td>\n",
              "      <td>20</td>\n",
              "      <td>KONKANI</td>\n",
              "      <td>['Marathi']</td>\n",
              "      <td>...</td>\n",
              "      <td>22.061460</td>\n",
              "      <td>24.732733</td>\n",
              "      <td>34.868406</td>\n",
              "      <td>-0.004719</td>\n",
              "      <td>-0.013178</td>\n",
              "      <td>-0.026895</td>\n",
              "      <td>0.013511</td>\n",
              "      <td>-0.005459</td>\n",
              "      <td>-0.003941</td>\n",
              "      <td>Karnataka</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>8902498</td>\n",
              "      <td>IISc_VaaniProject_M_JH_Jamtara_Akas11827_11033...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Jamtara/IISc_...</td>\n",
              "      <td>Jharkhand</td>\n",
              "      <td>male</td>\n",
              "      <td>815355</td>\n",
              "      <td>Jamtara</td>\n",
              "      <td>21</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>21.240514</td>\n",
              "      <td>21.517392</td>\n",
              "      <td>20.198155</td>\n",
              "      <td>0.003010</td>\n",
              "      <td>-0.009109</td>\n",
              "      <td>-0.032372</td>\n",
              "      <td>0.078265</td>\n",
              "      <td>-0.018999</td>\n",
              "      <td>0.017004</td>\n",
              "      <td>Chhattisgarh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>8902501</td>\n",
              "      <td>IISc_VaaniProject_M_JH_Jamtara_Akas11827_11005...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Jamtara/IISc_...</td>\n",
              "      <td>Jharkhand</td>\n",
              "      <td>male</td>\n",
              "      <td>815355</td>\n",
              "      <td>Jamtara</td>\n",
              "      <td>21</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>21.090096</td>\n",
              "      <td>21.503910</td>\n",
              "      <td>19.982245</td>\n",
              "      <td>0.033440</td>\n",
              "      <td>-0.027626</td>\n",
              "      <td>-0.066554</td>\n",
              "      <td>0.024623</td>\n",
              "      <td>0.000802</td>\n",
              "      <td>0.023067</td>\n",
              "      <td>Chhattisgarh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>8902506</td>\n",
              "      <td>IISc_VaaniProject_M_JH_Jamtara_Akas11827_11153...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Jamtara/IISc_...</td>\n",
              "      <td>Jharkhand</td>\n",
              "      <td>male</td>\n",
              "      <td>815355</td>\n",
              "      <td>Jamtara</td>\n",
              "      <td>21</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>18.993091</td>\n",
              "      <td>22.431204</td>\n",
              "      <td>21.796884</td>\n",
              "      <td>-0.017036</td>\n",
              "      <td>0.003875</td>\n",
              "      <td>-0.016402</td>\n",
              "      <td>0.151669</td>\n",
              "      <td>-0.020153</td>\n",
              "      <td>-0.007222</td>\n",
              "      <td>Bihar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>8902513</td>\n",
              "      <td>IISc_VaaniProject_M_JH_Jamtara_Akas11827_10492...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Jamtara/IISc_...</td>\n",
              "      <td>Jharkhand</td>\n",
              "      <td>male</td>\n",
              "      <td>815355</td>\n",
              "      <td>Jamtara</td>\n",
              "      <td>21</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>19.517374</td>\n",
              "      <td>21.356589</td>\n",
              "      <td>23.658518</td>\n",
              "      <td>-0.023965</td>\n",
              "      <td>-0.009520</td>\n",
              "      <td>-0.012426</td>\n",
              "      <td>0.047171</td>\n",
              "      <td>-0.010807</td>\n",
              "      <td>-0.001349</td>\n",
              "      <td>AndhraPradesh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>8902546</td>\n",
              "      <td>IISc_VaaniProject_M_JH_Jamtara_Moni44669_08330...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Jamtara/IISc_...</td>\n",
              "      <td>Jharkhand</td>\n",
              "      <td>female</td>\n",
              "      <td>815354</td>\n",
              "      <td>Jamtara</td>\n",
              "      <td>13</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>22.737129</td>\n",
              "      <td>24.205310</td>\n",
              "      <td>16.363754</td>\n",
              "      <td>0.005788</td>\n",
              "      <td>0.024982</td>\n",
              "      <td>0.091583</td>\n",
              "      <td>-0.002971</td>\n",
              "      <td>0.015759</td>\n",
              "      <td>-0.022182</td>\n",
              "      <td>Jharkhand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>8902562</td>\n",
              "      <td>IISc_VaaniProject_M_JH_Jamtara_Moni44669_09120...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Jamtara/IISc_...</td>\n",
              "      <td>Jharkhand</td>\n",
              "      <td>female</td>\n",
              "      <td>815354</td>\n",
              "      <td>Jamtara</td>\n",
              "      <td>13</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>20.107297</td>\n",
              "      <td>22.062982</td>\n",
              "      <td>18.720584</td>\n",
              "      <td>0.017447</td>\n",
              "      <td>0.036438</td>\n",
              "      <td>0.025848</td>\n",
              "      <td>0.035064</td>\n",
              "      <td>0.011125</td>\n",
              "      <td>-0.010919</td>\n",
              "      <td>Jharkhand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2020253</td>\n",
              "      <td>IISc_VaaniProject_S_Uttarpradesh_Hamirpur_1421...</td>\n",
              "      <td>https://vaani.iisc.ac.in/Audios/Hamirpur/IISc_...</td>\n",
              "      <td>UttarPradesh</td>\n",
              "      <td>male</td>\n",
              "      <td>210502</td>\n",
              "      <td>Hamirpur</td>\n",
              "      <td>Hamirpur(21)</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>21.761462</td>\n",
              "      <td>18.297386</td>\n",
              "      <td>18.082116</td>\n",
              "      <td>0.053892</td>\n",
              "      <td>-0.000788</td>\n",
              "      <td>-0.098290</td>\n",
              "      <td>-0.134976</td>\n",
              "      <td>-0.039377</td>\n",
              "      <td>-0.029764</td>\n",
              "      <td>Jharkhand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2023315</td>\n",
              "      <td>IISc_VaaniProject_S_Uttarpradesh_Hamirpur_1463...</td>\n",
              "      <td>https://vaani.iisc.ac.in/Audios/Hamirpur/IISc_...</td>\n",
              "      <td>UttarPradesh</td>\n",
              "      <td>male</td>\n",
              "      <td>210507</td>\n",
              "      <td>Hamirpur</td>\n",
              "      <td>Hamirpur(40)</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>22.392923</td>\n",
              "      <td>22.584244</td>\n",
              "      <td>16.426298</td>\n",
              "      <td>-0.057120</td>\n",
              "      <td>0.015544</td>\n",
              "      <td>0.085747</td>\n",
              "      <td>0.086586</td>\n",
              "      <td>-0.037201</td>\n",
              "      <td>-0.034397</td>\n",
              "      <td>Goa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2023770</td>\n",
              "      <td>IISc_VaaniProject_S_Uttarpradesh_Hamirpur_1373...</td>\n",
              "      <td>https://vaani.iisc.ac.in/Audios/Hamirpur/IISc_...</td>\n",
              "      <td>UttarPradesh</td>\n",
              "      <td>female</td>\n",
              "      <td>176043</td>\n",
              "      <td>Hamirpur</td>\n",
              "      <td>Hamirpur(30)</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>20.176789</td>\n",
              "      <td>28.414108</td>\n",
              "      <td>17.073517</td>\n",
              "      <td>-0.016806</td>\n",
              "      <td>-0.015444</td>\n",
              "      <td>0.026867</td>\n",
              "      <td>-0.078157</td>\n",
              "      <td>0.009037</td>\n",
              "      <td>0.008960</td>\n",
              "      <td>Chhattisgarh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2025055</td>\n",
              "      <td>IISc_VaaniProject_S_Uttarpradesh_Hamirpur_1464...</td>\n",
              "      <td>https://vaani.iisc.ac.in/Audios/Hamirpur/IISc_...</td>\n",
              "      <td>UttarPradesh</td>\n",
              "      <td>male</td>\n",
              "      <td>177029</td>\n",
              "      <td>Hamirpur</td>\n",
              "      <td>Hamirpur(40)</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>19.274688</td>\n",
              "      <td>19.594370</td>\n",
              "      <td>31.871490</td>\n",
              "      <td>-0.122455</td>\n",
              "      <td>0.052329</td>\n",
              "      <td>0.039435</td>\n",
              "      <td>-0.225275</td>\n",
              "      <td>0.009150</td>\n",
              "      <td>-0.073878</td>\n",
              "      <td>Rajasthan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2044205</td>\n",
              "      <td>IISc_VaaniProject_S_Uttarpradesh_Hamirpur_1312...</td>\n",
              "      <td>https://vaani.iisc.ac.in/Audios/Hamirpur/IISc_...</td>\n",
              "      <td>UttarPradesh</td>\n",
              "      <td>male</td>\n",
              "      <td>210341</td>\n",
              "      <td>Hamirpur</td>\n",
              "      <td>Hamirpur(27)</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>18.085065</td>\n",
              "      <td>17.635143</td>\n",
              "      <td>18.427341</td>\n",
              "      <td>0.053605</td>\n",
              "      <td>-0.002327</td>\n",
              "      <td>-0.026504</td>\n",
              "      <td>0.110849</td>\n",
              "      <td>-0.011136</td>\n",
              "      <td>-0.014266</td>\n",
              "      <td>Rajasthan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2042854</td>\n",
              "      <td>IISc_VaaniProject_S_Uttarpradesh_Hamirpur_1288...</td>\n",
              "      <td>https://vaani.iisc.ac.in/Audios/Hamirpur/IISc_...</td>\n",
              "      <td>UttarPradesh</td>\n",
              "      <td>female</td>\n",
              "      <td>174305</td>\n",
              "      <td>Hamirpur</td>\n",
              "      <td>Hamirpur(22)</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>21.792511</td>\n",
              "      <td>22.876662</td>\n",
              "      <td>20.172045</td>\n",
              "      <td>-0.013297</td>\n",
              "      <td>0.022767</td>\n",
              "      <td>0.084327</td>\n",
              "      <td>0.084536</td>\n",
              "      <td>-0.001824</td>\n",
              "      <td>-0.023511</td>\n",
              "      <td>WestBengal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2045302</td>\n",
              "      <td>IISc_VaaniProject_S_Uttarpradesh_Hamirpur_1392...</td>\n",
              "      <td>https://vaani.iisc.ac.in/Audios/Hamirpur/IISc_...</td>\n",
              "      <td>UttarPradesh</td>\n",
              "      <td>female</td>\n",
              "      <td>177030</td>\n",
              "      <td>Hamirpur</td>\n",
              "      <td>Hamirpur(27)</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>22.658528</td>\n",
              "      <td>22.944902</td>\n",
              "      <td>19.639080</td>\n",
              "      <td>-0.072920</td>\n",
              "      <td>0.024703</td>\n",
              "      <td>0.007112</td>\n",
              "      <td>-0.122862</td>\n",
              "      <td>0.017660</td>\n",
              "      <td>-0.024392</td>\n",
              "      <td>Bihar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2045301</td>\n",
              "      <td>IISc_VaaniProject_S_Uttarpradesh_Hamirpur_1392...</td>\n",
              "      <td>https://vaani.iisc.ac.in/Audios/Hamirpur/IISc_...</td>\n",
              "      <td>UttarPradesh</td>\n",
              "      <td>female</td>\n",
              "      <td>177030</td>\n",
              "      <td>Hamirpur</td>\n",
              "      <td>Hamirpur(27)</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>24.613697</td>\n",
              "      <td>22.486710</td>\n",
              "      <td>18.036577</td>\n",
              "      <td>-0.051546</td>\n",
              "      <td>-0.032764</td>\n",
              "      <td>0.079223</td>\n",
              "      <td>-0.177445</td>\n",
              "      <td>-0.011134</td>\n",
              "      <td>-0.054092</td>\n",
              "      <td>Bihar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>2048252</td>\n",
              "      <td>IISc_VaaniProject_S_Uttarpradesh_Hamirpur_1309...</td>\n",
              "      <td>https://vaani.iisc.ac.in/Audios/Hamirpur/IISc_...</td>\n",
              "      <td>UttarPradesh</td>\n",
              "      <td>male</td>\n",
              "      <td>210341</td>\n",
              "      <td>Hamirpur</td>\n",
              "      <td>Hamirpur(45)</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>17.528451</td>\n",
              "      <td>17.183736</td>\n",
              "      <td>16.128407</td>\n",
              "      <td>-0.002045</td>\n",
              "      <td>-0.009768</td>\n",
              "      <td>0.068103</td>\n",
              "      <td>-0.117610</td>\n",
              "      <td>-0.000703</td>\n",
              "      <td>-0.023669</td>\n",
              "      <td>UttarPradesh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>7563707</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_Nita36727_144641...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>male</td>\n",
              "      <td>854325</td>\n",
              "      <td>Araria</td>\n",
              "      <td>21</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>24.213826</td>\n",
              "      <td>29.381877</td>\n",
              "      <td>14.743478</td>\n",
              "      <td>0.033548</td>\n",
              "      <td>0.011172</td>\n",
              "      <td>-0.025681</td>\n",
              "      <td>-0.073708</td>\n",
              "      <td>-0.039746</td>\n",
              "      <td>0.011990</td>\n",
              "      <td>Jharkhand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>7563721</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_71981266_1247070...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>female</td>\n",
              "      <td>854328</td>\n",
              "      <td>Araria</td>\n",
              "      <td>39</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>21.145171</td>\n",
              "      <td>23.260481</td>\n",
              "      <td>31.949563</td>\n",
              "      <td>0.014118</td>\n",
              "      <td>-0.005542</td>\n",
              "      <td>0.056249</td>\n",
              "      <td>-0.050925</td>\n",
              "      <td>0.005657</td>\n",
              "      <td>0.001793</td>\n",
              "      <td>Chhattisgarh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>7563709</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_Nita36727_144844...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>male</td>\n",
              "      <td>854325</td>\n",
              "      <td>Araria</td>\n",
              "      <td>21</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>25.709413</td>\n",
              "      <td>35.111273</td>\n",
              "      <td>14.684528</td>\n",
              "      <td>0.025488</td>\n",
              "      <td>0.024609</td>\n",
              "      <td>0.015288</td>\n",
              "      <td>-0.115441</td>\n",
              "      <td>-0.032343</td>\n",
              "      <td>0.001734</td>\n",
              "      <td>Maharashtra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>7563714</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_Nita36727_144641...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>male</td>\n",
              "      <td>854325</td>\n",
              "      <td>Araria</td>\n",
              "      <td>21</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>24.790419</td>\n",
              "      <td>33.726518</td>\n",
              "      <td>14.984811</td>\n",
              "      <td>-0.015004</td>\n",
              "      <td>-0.089572</td>\n",
              "      <td>-0.149736</td>\n",
              "      <td>-0.045910</td>\n",
              "      <td>-0.001094</td>\n",
              "      <td>-0.050903</td>\n",
              "      <td>Telangana</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>7563713</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_Rahu87667_001310...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>male</td>\n",
              "      <td>854328</td>\n",
              "      <td>Araria</td>\n",
              "      <td>23</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>21.786797</td>\n",
              "      <td>26.326641</td>\n",
              "      <td>16.187632</td>\n",
              "      <td>0.004982</td>\n",
              "      <td>-0.054480</td>\n",
              "      <td>-0.004590</td>\n",
              "      <td>0.063494</td>\n",
              "      <td>-0.009028</td>\n",
              "      <td>-0.021561</td>\n",
              "      <td>Jharkhand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>7563717</td>\n",
              "      <td>IISc_VaaniProject_M_BR_Araria_Rahu87667_001310...</td>\n",
              "      <td>https://vaani.iisc.ac.in//Audios/Araria/IISc_V...</td>\n",
              "      <td>Bihar</td>\n",
              "      <td>male</td>\n",
              "      <td>854328</td>\n",
              "      <td>Araria</td>\n",
              "      <td>23</td>\n",
              "      <td>HINDI</td>\n",
              "      <td>['Hindi']</td>\n",
              "      <td>...</td>\n",
              "      <td>19.801884</td>\n",
              "      <td>23.499042</td>\n",
              "      <td>15.239035</td>\n",
              "      <td>-0.014291</td>\n",
              "      <td>0.012650</td>\n",
              "      <td>-0.080028</td>\n",
              "      <td>0.104683</td>\n",
              "      <td>0.014374</td>\n",
              "      <td>-0.000841</td>\n",
              "      <td>Telangana</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>45 rows × 49 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4803805f-8b10-41ee-908c-d86ce67bc617')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4803805f-8b10-41ee-908c-d86ce67bc617 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4803805f-8b10-41ee-908c-d86ce67bc617');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-01f44595-138a-4f42-b086-c7b1a4fa6a92\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-01f44595-138a-4f42-b086-c7b1a4fa6a92')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-01f44595-138a-4f42-b086-c7b1a4fa6a92 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_69a844ce-dd27-4240-a78d-14238be8650e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('new_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_69a844ce-dd27-4240-a78d-14238be8650e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('new_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "new_df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accur=accuracy_score(new_df['state'],new_df['predicted_state'])\n",
        "print(accur)\n",
        "df['languagesSpoken'].value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "ZeDAfYD0MWti",
        "outputId": "e67e92ad-ede2-46d0-c346-cf65c5c1abb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.35555555555555557\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "languagesSpoken\n",
              "['Hindi']                          30688\n",
              "['Telugu']                          9517\n",
              "['Rajasthani']                      6244\n",
              "['Kannada']                         4664\n",
              "['Marathi']                         3669\n",
              "                                   ...  \n",
              "['Telugu', 'Tamil', 'English']         2\n",
              "['Gondi']                              2\n",
              "['Hindi', 'Marathi']                   1\n",
              "['Hindi', 'Konkani', 'English']        1\n",
              "['Bengali', 'Hindi', 'English']        1\n",
              "Name: count, Length: 133, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>languagesSpoken</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>['Hindi']</th>\n",
              "      <td>30688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>['Telugu']</th>\n",
              "      <td>9517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>['Rajasthani']</th>\n",
              "      <td>6244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>['Kannada']</th>\n",
              "      <td>4664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>['Marathi']</th>\n",
              "      <td>3669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>['Telugu', 'Tamil', 'English']</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>['Gondi']</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>['Hindi', 'Marathi']</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>['Hindi', 'Konkani', 'English']</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>['Bengali', 'Hindi', 'English']</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>133 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# 1️⃣ Load Data from CSV\n",
        "# ==============================\n",
        "csv_file_path = \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/merged_data.csv\"\n",
        "df = pd.read_csv(csv_file_path)\n",
        "print(df.columns)\n",
        "\n",
        "# ==============================\n",
        "# 2️⃣ Prepare Data (Separate Features & Labels)\n",
        "# ==============================\n",
        "X = df.drop(columns=['id', 'filename', 'file_url', 'gender', 'pincode', 'district',\n",
        "                   'stayYears', 'assertLanguage', 'languagesSpoken'])  # Features\n",
        "y = df['assertLanguage']  # Target variable (predicting language)\n",
        "\n",
        "# Encode categorical features and labels\n",
        "state_encoder = LabelEncoder()\n",
        "language_encoder = LabelEncoder()\n",
        "\n",
        "# Encode state column if it exists\n",
        "if 'state' in X.columns:\n",
        "    X['state'] = state_encoder.fit_transform(X['state'])\n",
        "\n",
        "y = language_encoder.fit_transform(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIZgS19gMkkd",
        "outputId": "9616cc68-9f77-4e9c-dd1b-270bf418cae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'filename', 'file_url', 'state', 'gender', 'pincode', 'district',\n",
            "       'stayYears', 'assertLanguage', 'languagesSpoken', 'feature_0',\n",
            "       'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5',\n",
            "       'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10',\n",
            "       'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15',\n",
            "       'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20',\n",
            "       'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25',\n",
            "       'feature_26', 'feature_27', 'feature_28', 'feature_29', 'feature_30',\n",
            "       'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_35',\n",
            "       'feature_36', 'feature_37'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: classes of language encoder\n",
        "\n",
        "# Get the unique classes (languages) from the encoded labels\n",
        "language_classes = list(language_encoder.classes_)\n",
        "\n",
        "print(\"Language Classes:\")\n",
        "language_classes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diYPJrleMw6K",
        "outputId": "5e49edcc-4aae-4679-d981-ed9d4b125454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Language Classes:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BENGALI',\n",
              " 'BHATRI',\n",
              " 'CHATTISGARHI',\n",
              " 'GONDI',\n",
              " 'HALBI',\n",
              " 'HINDI',\n",
              " 'KANNADA',\n",
              " 'KHORTHA',\n",
              " 'KONKANI',\n",
              " 'MAITHILI',\n",
              " 'MARATHI',\n",
              " 'MARWARI',\n",
              " 'RAJASTHANI',\n",
              " 'TELUGU',\n",
              " 'URDU']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# You can access the numerical representation of each language using:\n",
        "# language_encoder.transform(['Hindi', 'English'])\n",
        "\n",
        "# You can get the original language name using:\n",
        "# language_encoder.inverse_transform([0, 1])\n",
        "\n",
        "# ==============================\n",
        "# 3️⃣ Build BiLSTM Model for Language Prediction\n",
        "# ==============================\n",
        "\n",
        "# Split data into train & test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "# Set n_neighbors to 1 since you have only 2 samples in the minority class\n",
        "sm = SMOTE(k_neighbors=1)\n",
        "\n",
        "# Apply SMOTE\n",
        "X_sm_train, y_sm_train = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f'''Shape of X before SMOTE: {X_train.shape}\n",
        "Shape of X after SMOTE: {X_sm_train.shape}''')\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_sm_train_scaled = scaler.fit_transform(X_sm_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape for LSTM (samples, time steps, features)\n",
        "X_train_reshaped = X_sm_train_scaled.reshape(X_sm_train_scaled.shape[0], 1, X_sm_train_scaled.shape[1])\n",
        "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train_categorical = to_categorical(y_sm_train)\n",
        "y_test_categorical = to_categorical(y_test)\n",
        "\n",
        "# Build BiLSTM model for language prediction\n",
        "model_language = Sequential([\n",
        "    Input(shape=(1, X_sm_train_scaled.shape[1])),\n",
        "    Bidirectional(LSTM(256, return_sequences=True)),\n",
        "    Dropout(0.3),\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),\n",
        "    Dropout(0.3),\n",
        "    Bidirectional(LSTM(64, return_sequences=False)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(len(language_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_language.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=10,         # Number of epochs to wait before stopping if no improvement\n",
        "    restore_best_weights=True  # Restore the model weights from the epoch with the best validation loss\n",
        ")\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model_language.fit(\n",
        "    X_train_reshaped, y_train_categorical,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_reshaped, y_test_categorical),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "\n",
        "# Save the trained model\n",
        "model_language.save('/content/drive/MyDrive/language_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "dtH_PLPuMnwf",
        "outputId": "a3286346-2293-45c8-b033-273c2f93db05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Language Classes:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'SMOTE' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7dc5550e2d48>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Set n_neighbors to 1 since you have only 2 samples in the minority class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Apply SMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SMOTE' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for training model for predicting languages based on predicted state"
      ],
      "metadata": {
        "id": "GO75eaQtSmId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ==============================\n",
        "# 3️⃣ Train-Test Split\n",
        "# ==============================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.4, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# 4️⃣ Handle Class Imbalance (SMOTE on training data only)\n",
        "\n",
        "# ==============================\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "sm = RandomOverSampler()\n",
        "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f'''Shape before SMOTE: {X_train.shape}\n",
        "Shape after SMOTE: {X_train_sm.shape}''')\n",
        "\n",
        "# ==============================\n",
        "# 5️⃣ Feature Scaling\n",
        "# ==============================\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_sm)\n",
        "X_test_scaled = scaler.transform(X_test)  # Use same scaler on test data\n",
        "\n",
        "# ==============================\n",
        "# 6️⃣ Reshape for LSTM and One-Hot Encoding\n",
        "# ==============================\n",
        "# Reshape for LSTM (samples, time steps, features)\n",
        "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
        "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
        "\n",
        "# One-hot encode the target variables\n",
        "y_train_categorical = to_categorical(y_train_sm)\n",
        "y_test_categorical = to_categorical(y_test)\n",
        "\n",
        "# ==============================\n",
        "# 7️⃣ Build BiLSTM Model\n",
        "# ==============================\n",
        "model = Sequential([\n",
        "    Input(shape=(1, X_train_scaled.shape[1])),  # Input shape based on features\n",
        "    Bidirectional(LSTM(256, return_sequences=True)),\n",
        "    Dropout(0.3),\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),\n",
        "    Dropout(0.3),\n",
        "    Bidirectional(LSTM(64, return_sequences=False)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(len(language_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# 8️⃣ Train Model\n",
        "# ==============================\n",
        "history = model.fit(\n",
        "    X_train_reshaped, y_train_categorical,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_reshaped, y_test_categorical),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# 9️⃣ Save and Evaluate Model\n",
        "# ==============================\n",
        "model.save('/content/drive/MyDrive/my_trained_model_for_language.h5')\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test_categorical)\n",
        "print(f\"BiLSTM Model Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Number of classes: {len(language_encoder.classes_)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKl2NHh9RGfl",
        "outputId": "75336ff2-eccc-4465-8488-d8da62c975ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'filename', 'file_url', 'state', 'gender', 'pincode', 'district',\n",
            "       'stayYears', 'assertLanguage', 'languagesSpoken', 'feature_0',\n",
            "       'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5',\n",
            "       'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10',\n",
            "       'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15',\n",
            "       'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20',\n",
            "       'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25',\n",
            "       'feature_26', 'feature_27', 'feature_28', 'feature_29', 'feature_30',\n",
            "       'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_35',\n",
            "       'feature_36', 'feature_37'],\n",
            "      dtype='object')\n",
            "Shape before SMOTE: (44390, 39)\n",
            "Shape after SMOTE: (291570, 39)\n",
            "Epoch 1/100\n",
            "\u001b[1m9112/9112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 13ms/step - accuracy: 0.7926 - loss: 0.5860 - val_accuracy: 0.8783 - val_loss: 0.3346\n",
            "Epoch 2/100\n",
            "\u001b[1m9112/9112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 13ms/step - accuracy: 0.9528 - loss: 0.1266 - val_accuracy: 0.9227 - val_loss: 0.2228\n",
            "Epoch 3/100\n",
            "\u001b[1m9112/9112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 13ms/step - accuracy: 0.9702 - loss: 0.0838 - val_accuracy: 0.9249 - val_loss: 0.2269\n",
            "Epoch 4/100\n",
            "\u001b[1m9112/9112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 13ms/step - accuracy: 0.9770 - loss: 0.0674 - val_accuracy: 0.9382 - val_loss: 0.1863\n",
            "Epoch 5/100\n",
            "\u001b[1m9112/9112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 13ms/step - accuracy: 0.9817 - loss: 0.0544 - val_accuracy: 0.9468 - val_loss: 0.1600\n",
            "Epoch 6/100\n",
            "\u001b[1m9112/9112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 12ms/step - accuracy: 0.9845 - loss: 0.0471 - val_accuracy: 0.9474 - val_loss: 0.1852\n",
            "Epoch 7/100\n",
            "\u001b[1m9112/9112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 13ms/step - accuracy: 0.9869 - loss: 0.0397 - val_accuracy: 0.9532 - val_loss: 0.1702\n",
            "Epoch 8/100\n",
            "\u001b[1m9112/9112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 13ms/step - accuracy: 0.9878 - loss: 0.0378 - val_accuracy: 0.9557 - val_loss: 0.1606\n",
            "Epoch 9/100\n",
            "\u001b[1m9112/9112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 12ms/step - accuracy: 0.9900 - loss: 0.0319 - val_accuracy: 0.9561 - val_loss: 0.1612\n",
            "Epoch 10/100\n",
            "\u001b[1m9112/9112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 13ms/step - accuracy: 0.9908 - loss: 0.0301 - val_accuracy: 0.9571 - val_loss: 0.1724\n",
            "Epoch 11/100\n",
            "\u001b[1m9112/9112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 13ms/step - accuracy: 0.9913 - loss: 0.0282 - val_accuracy: 0.9578 - val_loss: 0.1696\n",
            "Epoch 12/100\n",
            "\u001b[1m9112/9112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 13ms/step - accuracy: 0.9920 - loss: 0.0260 - val_accuracy: 0.9598 - val_loss: 0.1640\n",
            "Epoch 13/100\n",
            "\u001b[1m9112/9112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 13ms/step - accuracy: 0.9925 - loss: 0.0252 - val_accuracy: 0.9615 - val_loss: 0.1687\n",
            "Epoch 14/100\n",
            "\u001b[1m9112/9112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 13ms/step - accuracy: 0.9931 - loss: 0.0241 - val_accuracy: 0.9612 - val_loss: 0.1784\n",
            "Epoch 15/100\n",
            "\u001b[1m9112/9112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 13ms/step - accuracy: 0.9932 - loss: 0.0230 - val_accuracy: 0.9600 - val_loss: 0.1750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9473 - loss: 0.1591\n",
            "BiLSTM Model Accuracy: 0.9468\n",
            "Number of classes: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for predicting the language on test audios as well.\n"
      ],
      "metadata": {
        "id": "ZYUQUXI9StYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==============================\n",
        "# 1️⃣ Load Data from CSV\n",
        "# ==============================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# ==============================\n",
        "# 1️⃣ Load the Saved Model\n",
        "# ==============================\n",
        "model = load_model('/content/drive/MyDrive/my_trained_model_for_language.h5')\n",
        "\n",
        "# ==============================\n",
        "# 2️⃣ Load and Preprocess the New Dataset\n",
        "# ==============================\n",
        "# Load the new dataset\n",
        "new_df\n",
        "\n",
        "# Ensure the new dataset has the same columns as the training data\n",
        "# Drop the same columns as during training\n",
        "X_new = new_df.drop(columns=['id', 'filename', 'file_url', 'state', 'gender', 'pincode', 'district',\n",
        "                            'stayYears', 'assertLanguage', 'languagesSpoken'])\n",
        "X_new['state']=state_encoder.transform(X_new['predicted_state'])\n",
        "\n",
        "X_new=X_new.drop(columns=['predicted_state'])\n",
        "\n",
        "X_new=X_new[['state', 'feature_0', 'feature_1', 'feature_2', 'feature_3',\n",
        "       'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8',\n",
        "       'feature_9', 'feature_10', 'feature_11', 'feature_12', 'feature_13',\n",
        "       'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18',\n",
        "       'feature_19', 'feature_20', 'feature_21', 'feature_22', 'feature_23',\n",
        "       'feature_24', 'feature_25', 'feature_26', 'feature_27', 'feature_28',\n",
        "       'feature_29', 'feature_30', 'feature_31', 'feature_32', 'feature_33',\n",
        "       'feature_34', 'feature_35', 'feature_36', 'feature_37']]\n",
        "# Normalize the new data using the same scaler as during training\n",
        "# (Assuming you saved the scaler during training; otherwise, refit it)\n",
        "scaler = StandardScaler()\n",
        "X_new = scaler.fit_transform(X_new)  # Use the same scaler as during training\n",
        "\n",
        "# Reshape for LSTM (samples, time steps, features)\n",
        "X_new = X_new.reshape(X_new.shape[0], 1, X_new.shape[1])\n",
        "\n",
        "# ==============================\n",
        "# 3️⃣ Make Predictions\n",
        "# ==============================\n",
        "# Predict on the new data\n",
        "predictions = model.predict(X_new)\n",
        "\n",
        "# Convert predictions from probabilities to class labels\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# ==============================\n",
        "# 4️⃣ Decode Predictions\n",
        "# ==============================\n",
        "\n",
        "\n",
        "# Decode the predicted classes back to state names\n",
        "predicted_language = language_encoder.inverse_transform(predicted_classes)\n",
        "\n",
        "# Add the predicted states to the new dataset\n",
        "new_df['predicted_language'] = predicted_language\n",
        "\n",
        "# ==============================\n",
        "# 5️⃣ Save or Display Results\n",
        "# ==============================\n",
        "# Save the new dataset with predictions to a CSV file\n",
        "new_df.to_csv('new_dataset_with_predictions.csv', index=False)\n",
        "\n",
        "# Display the first few rows with predictions\n",
        "print(new_df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQPivFosM3iH",
        "outputId": "34c429e1-5560-4ab4-9a2b-af0298c56cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449ms/step\n",
            "        id                                           filename  \\\n",
            "0  7563707  IISc_VaaniProject_M_BR_Araria_Nita36727_144641...   \n",
            "1  7563721  IISc_VaaniProject_M_BR_Araria_71981266_1247070...   \n",
            "2  7563709  IISc_VaaniProject_M_BR_Araria_Nita36727_144844...   \n",
            "3  7563714  IISc_VaaniProject_M_BR_Araria_Nita36727_144641...   \n",
            "4  7563713  IISc_VaaniProject_M_BR_Araria_Rahu87667_001310...   \n",
            "\n",
            "                                            file_url  state  gender  pincode  \\\n",
            "0  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...  Bihar    male   854325   \n",
            "1  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...  Bihar  female   854328   \n",
            "2  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...  Bihar    male   854325   \n",
            "3  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...  Bihar    male   854325   \n",
            "4  https://vaani.iisc.ac.in//Audios/Araria/IISc_V...  Bihar    male   854328   \n",
            "\n",
            "  district stayYears assertLanguage languagesSpoken  ...  feature_30  \\\n",
            "0   Araria        21          HINDI       ['Hindi']  ...   29.381877   \n",
            "1   Araria        39          HINDI       ['Hindi']  ...   23.260481   \n",
            "2   Araria        21          HINDI       ['Hindi']  ...   35.111273   \n",
            "3   Araria        21          HINDI       ['Hindi']  ...   33.726518   \n",
            "4   Araria        23          HINDI       ['Hindi']  ...   26.326641   \n",
            "\n",
            "   feature_31  feature_32  feature_33  feature_34  feature_35  feature_36  \\\n",
            "0   14.743478    0.033548    0.011172   -0.025681   -0.073708   -0.039746   \n",
            "1   31.949563    0.014118   -0.005542    0.056249   -0.050925    0.005657   \n",
            "2   14.684528    0.025488    0.024609    0.015288   -0.115441   -0.032343   \n",
            "3   14.984811   -0.015004   -0.089572   -0.149736   -0.045910   -0.001094   \n",
            "4   16.187632    0.004982   -0.054480   -0.004590    0.063494   -0.009028   \n",
            "\n",
            "   feature_37  predicted_state  predicted_language  \n",
            "0    0.011990        Jharkhand             KONKANI  \n",
            "1    0.001793     Chhattisgarh               HINDI  \n",
            "2    0.001734      Maharashtra             KANNADA  \n",
            "3   -0.050903        Telangana             MARWARI  \n",
            "4   -0.021561        Jharkhand               HINDI  \n",
            "\n",
            "[5 rows x 50 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accur1=accuracy_score(new_df['assertLanguage'],new_df['predicted_language'])\n",
        "print(accur1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RS_BmEsU5yR",
        "outputId": "5c132b6b-6dd3-4978-e80a-261cf98a03c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4222222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MHA (Sakshi) (RUN IN JUPYTER NOTEBOOK)\n"
      ],
      "metadata": {
        "id": "vTEHXwW7aWo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UGZ7g53V1zq",
        "outputId": "c6e49f4b-0d7e-407d-8e1b-e0ae4917e45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, MultiHeadAttention, LayerNormalization, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# ==============================\n",
        "# 1️⃣ Load Training Data\n",
        "# ==============================\n",
        "csv_file_path = \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/merged_data.csv\"\n",
        "df = pd.read_csv(csv_file_path)\n",
        "print(\"✅ Loaded training data!\")\n",
        "\n",
        "# ==============================\n",
        "# 2️⃣ Preprocess Data\n",
        "# ==============================\n",
        "X = df.drop(columns=['id', 'filename', 'file_url', 'gender', 'pincode', 'district',\n",
        "                     'stayYears', 'assertLanguage', 'languagesSpoken', 'state'], errors='ignore')\n",
        "y = df['assertLanguage']\n",
        "\n",
        "# Encode labels\n",
        "language_encoder = LabelEncoder()\n",
        "y = language_encoder.fit_transform(y)\n",
        "\n",
        "# Save Label Encoder\n",
        "joblib.dump(language_encoder,\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/Vaani MHA/language_encoder.pkl\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
        "\n",
        "# Save training feature names\n",
        "train_feature_names = list(X_train.columns)\n",
        "joblib.dump(train_feature_names, \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/Vaani MHA/train_feature_names.pkl\")\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Save Scaler\n",
        "joblib.dump(scaler, \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/Vaani MHA/scaler.pkl\")\n",
        "\n",
        "# Reshape for Multi-Head Attention\n",
        "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
        "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train_categorical = to_categorical(y_train, num_classes=len(language_encoder.classes_))\n",
        "y_test_categorical = to_categorical(y_test, num_classes=len(language_encoder.classes_))\n",
        "\n",
        "print(\"✅ Preprocessing done!\")\n",
        "\n",
        "# ==============================\n",
        "# 3️⃣ Define Multi-Head Attention Model (Functional API)\n",
        "# ==============================\n",
        "input_layer = Input(shape=(1, X_train.shape[1]))\n",
        "\n",
        "# Multi-Head Attention Layer\n",
        "attention_output = MultiHeadAttention(num_heads=4, key_dim=32)(input_layer, input_layer)\n",
        "attention_output = LayerNormalization(epsilon=1e-6)(attention_output)\n",
        "\n",
        "# Flatten and Fully Connected Layers\n",
        "x = Flatten()(attention_output)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "output_layer = Dense(len(language_encoder.classes_), activation='softmax')(x)\n",
        "\n",
        "# Create Model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# ==============================\n",
        "# 4️⃣ Train the Model\n",
        "# ==============================\n",
        "history = model.fit(\n",
        "    X_train_reshaped, y_train_categorical,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_reshaped, y_test_categorical),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# 5️⃣ Save Model\n",
        "# ==============================\n",
        "model.save(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/Vaani MHA/final colab.h5\")\n",
        "print(\"✅ Model training complete and saved!\")\n"
      ],
      "metadata": {
        "id": "B96-LrtJamSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42dbb247-c25d-4377-8934-fa58cda1d989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded training data!\n",
            "✅ Preprocessing done!\n",
            "Epoch 1/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.4755 - loss: 1.6885 - val_accuracy: 0.5927 - val_loss: 1.2501\n",
            "Epoch 2/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5798 - loss: 1.3133 - val_accuracy: 0.6183 - val_loss: 1.1609\n",
            "Epoch 3/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6017 - loss: 1.2295 - val_accuracy: 0.6498 - val_loss: 1.0907\n",
            "Epoch 4/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6149 - loss: 1.1936 - val_accuracy: 0.6493 - val_loss: 1.0601\n",
            "Epoch 5/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6276 - loss: 1.1534 - val_accuracy: 0.6641 - val_loss: 1.0389\n",
            "Epoch 6/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.6342 - loss: 1.1296 - val_accuracy: 0.6577 - val_loss: 1.0214\n",
            "Epoch 7/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6339 - loss: 1.1170 - val_accuracy: 0.6776 - val_loss: 0.9915\n",
            "Epoch 8/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6452 - loss: 1.0955 - val_accuracy: 0.6747 - val_loss: 0.9905\n",
            "Epoch 9/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6427 - loss: 1.0948 - val_accuracy: 0.6866 - val_loss: 0.9624\n",
            "Epoch 10/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.6473 - loss: 1.0692 - val_accuracy: 0.6869 - val_loss: 0.9575\n",
            "Epoch 11/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6499 - loss: 1.0784 - val_accuracy: 0.6862 - val_loss: 0.9490\n",
            "Epoch 12/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6530 - loss: 1.0601 - val_accuracy: 0.6918 - val_loss: 0.9404\n",
            "Epoch 13/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6565 - loss: 1.0454 - val_accuracy: 0.6967 - val_loss: 0.9338\n",
            "Epoch 14/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6537 - loss: 1.0579 - val_accuracy: 0.7015 - val_loss: 0.9222\n",
            "Epoch 15/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6522 - loss: 1.0566 - val_accuracy: 0.6944 - val_loss: 0.9285\n",
            "Epoch 16/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.6584 - loss: 1.0360 - val_accuracy: 0.6908 - val_loss: 0.9279\n",
            "Epoch 17/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6582 - loss: 1.0360 - val_accuracy: 0.7036 - val_loss: 0.9087\n",
            "Epoch 18/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6576 - loss: 1.0383 - val_accuracy: 0.7017 - val_loss: 0.9096\n",
            "Epoch 19/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6632 - loss: 1.0228 - val_accuracy: 0.6976 - val_loss: 0.9175\n",
            "Epoch 20/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6664 - loss: 1.0163 - val_accuracy: 0.7015 - val_loss: 0.9088\n",
            "Epoch 21/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.6625 - loss: 1.0294 - val_accuracy: 0.6971 - val_loss: 0.9136\n",
            "Epoch 22/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6638 - loss: 1.0211 - val_accuracy: 0.7021 - val_loss: 0.9040\n",
            "Epoch 23/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6651 - loss: 1.0114 - val_accuracy: 0.7086 - val_loss: 0.8926\n",
            "Epoch 24/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6681 - loss: 0.9965 - val_accuracy: 0.7027 - val_loss: 0.8967\n",
            "Epoch 25/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6651 - loss: 1.0162 - val_accuracy: 0.7074 - val_loss: 0.8921\n",
            "Epoch 26/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6654 - loss: 1.0096 - val_accuracy: 0.7080 - val_loss: 0.8859\n",
            "Epoch 27/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.6692 - loss: 1.0032 - val_accuracy: 0.7083 - val_loss: 0.8897\n",
            "Epoch 28/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6690 - loss: 1.0020 - val_accuracy: 0.7141 - val_loss: 0.8725\n",
            "Epoch 29/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6679 - loss: 1.0039 - val_accuracy: 0.7031 - val_loss: 0.8917\n",
            "Epoch 30/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6718 - loss: 0.9875 - val_accuracy: 0.7142 - val_loss: 0.8764\n",
            "Epoch 31/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6745 - loss: 0.9927 - val_accuracy: 0.7147 - val_loss: 0.8687\n",
            "Epoch 32/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.6708 - loss: 1.0011 - val_accuracy: 0.7110 - val_loss: 0.8796\n",
            "Epoch 33/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.6742 - loss: 0.9910 - val_accuracy: 0.7087 - val_loss: 0.8765\n",
            "Epoch 34/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6728 - loss: 0.9913 - val_accuracy: 0.7154 - val_loss: 0.8698\n",
            "Epoch 35/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6734 - loss: 0.9869 - val_accuracy: 0.7121 - val_loss: 0.8717\n",
            "Epoch 36/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6744 - loss: 0.9836 - val_accuracy: 0.7089 - val_loss: 0.8772\n",
            "Epoch 37/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6788 - loss: 0.9854 - val_accuracy: 0.7156 - val_loss: 0.8649\n",
            "Epoch 38/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6799 - loss: 0.9803 - val_accuracy: 0.7087 - val_loss: 0.8724\n",
            "Epoch 39/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6718 - loss: 0.9876 - val_accuracy: 0.7204 - val_loss: 0.8586\n",
            "Epoch 40/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6743 - loss: 0.9813 - val_accuracy: 0.7123 - val_loss: 0.8668\n",
            "Epoch 41/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6751 - loss: 0.9807 - val_accuracy: 0.7158 - val_loss: 0.8601\n",
            "Epoch 42/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6783 - loss: 0.9715 - val_accuracy: 0.7196 - val_loss: 0.8589\n",
            "Epoch 43/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6750 - loss: 0.9777 - val_accuracy: 0.7162 - val_loss: 0.8597\n",
            "Epoch 44/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.6778 - loss: 0.9719 - val_accuracy: 0.7185 - val_loss: 0.8573\n",
            "Epoch 45/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6787 - loss: 0.9735 - val_accuracy: 0.7225 - val_loss: 0.8538\n",
            "Epoch 46/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6788 - loss: 0.9706 - val_accuracy: 0.7208 - val_loss: 0.8549\n",
            "Epoch 47/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6810 - loss: 0.9632 - val_accuracy: 0.7219 - val_loss: 0.8510\n",
            "Epoch 48/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - accuracy: 0.6792 - loss: 0.9677 - val_accuracy: 0.7169 - val_loss: 0.8602\n",
            "Epoch 49/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.6829 - loss: 0.9531 - val_accuracy: 0.7202 - val_loss: 0.8504\n",
            "Epoch 50/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.6791 - loss: 0.9731 - val_accuracy: 0.7159 - val_loss: 0.8626\n",
            "Epoch 51/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6849 - loss: 0.9641 - val_accuracy: 0.7184 - val_loss: 0.8529\n",
            "Epoch 52/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.6846 - loss: 0.9490 - val_accuracy: 0.7190 - val_loss: 0.8523\n",
            "Epoch 53/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.6834 - loss: 0.9563 - val_accuracy: 0.7214 - val_loss: 0.8499\n",
            "Epoch 54/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6806 - loss: 0.9626 - val_accuracy: 0.7253 - val_loss: 0.8437\n",
            "Epoch 55/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.6827 - loss: 0.9585 - val_accuracy: 0.7208 - val_loss: 0.8504\n",
            "Epoch 56/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.6755 - loss: 0.9720 - val_accuracy: 0.7207 - val_loss: 0.8481\n",
            "Epoch 57/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6837 - loss: 0.9585 - val_accuracy: 0.7257 - val_loss: 0.8424\n",
            "Epoch 58/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.6821 - loss: 0.9690 - val_accuracy: 0.7229 - val_loss: 0.8407\n",
            "Epoch 59/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6889 - loss: 0.9496 - val_accuracy: 0.7226 - val_loss: 0.8479\n",
            "Epoch 60/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6856 - loss: 0.9540 - val_accuracy: 0.7242 - val_loss: 0.8417\n",
            "Epoch 61/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6848 - loss: 0.9584 - val_accuracy: 0.7160 - val_loss: 0.8552\n",
            "Epoch 62/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.6820 - loss: 0.9580 - val_accuracy: 0.7248 - val_loss: 0.8419\n",
            "Epoch 63/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6837 - loss: 0.9615 - val_accuracy: 0.7264 - val_loss: 0.8316\n",
            "Epoch 64/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6823 - loss: 0.9587 - val_accuracy: 0.7248 - val_loss: 0.8360\n",
            "Epoch 65/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6846 - loss: 0.9513 - val_accuracy: 0.7248 - val_loss: 0.8403\n",
            "Epoch 66/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6831 - loss: 0.9563 - val_accuracy: 0.7311 - val_loss: 0.8333\n",
            "Epoch 67/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6872 - loss: 0.9464 - val_accuracy: 0.7200 - val_loss: 0.8504\n",
            "Epoch 68/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6846 - loss: 0.9466 - val_accuracy: 0.7235 - val_loss: 0.8415\n",
            "Epoch 69/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6832 - loss: 0.9499 - val_accuracy: 0.7277 - val_loss: 0.8342\n",
            "Epoch 70/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6883 - loss: 0.9564 - val_accuracy: 0.7259 - val_loss: 0.8381\n",
            "Epoch 71/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.6859 - loss: 0.9437 - val_accuracy: 0.7288 - val_loss: 0.8355\n",
            "Epoch 72/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6874 - loss: 0.9427 - val_accuracy: 0.7167 - val_loss: 0.8507\n",
            "Epoch 73/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6891 - loss: 0.9386 - val_accuracy: 0.7240 - val_loss: 0.8393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model training complete and saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# ==============================\n",
        "# 1️⃣ Load Saved Model & Encoders\n",
        "# ==============================\n",
        "model_path = \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/Vaani MHA/final colab.h5\"\n",
        "encoder_path = \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/Vaani MHA/language_encoder.pkl\"\n",
        "scaler_path = \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/Vaani MHA/scaler.pkl\"\n",
        "feature_names_path = \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/Vaani MHA/train_feature_names.pkl\"\n",
        "\n",
        "# Load Model\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "print(\"✅ Model loaded successfully!\")\n",
        "\n",
        "# Load Label Encoder\n",
        "if os.path.exists(encoder_path):\n",
        "    language_encoder = joblib.load(encoder_path)\n",
        "else:\n",
        "    raise FileNotFoundError(\"🚨 Label Encoder file not found. Run training script first.\")\n",
        "\n",
        "# Load Scaler\n",
        "if os.path.exists(scaler_path):\n",
        "    scaler = joblib.load(scaler_path)\n",
        "else:\n",
        "    raise FileNotFoundError(\"🚨 Scaler file not found. Run training script first.\")\n",
        "\n",
        "# Load Training Feature Names\n",
        "if os.path.exists(feature_names_path):\n",
        "    train_feature_names = joblib.load(feature_names_path)\n",
        "else:\n",
        "    raise FileNotFoundError(\"🚨 Training feature names file not found. Run training script first.\")\n",
        "\n",
        "# ==============================\n",
        "# 2️⃣ Load and Process Test Data\n",
        "# ==============================\n",
        "test_csv_path =\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/test_audio_final.csv\"\n",
        "df_test = pd.read_csv(test_csv_path)\n",
        "\n",
        "# Extract actual labels before dropping columns\n",
        "actual_languages = df_test['assertLanguage'].tolist()  # Store actual languages\n",
        "\n",
        "# Drop unnecessary columns\n",
        "drop_columns = ['id', 'filename', 'file_url', 'gender', 'pincode', 'district',\n",
        "                'stayYears', 'assertLanguage', 'languagesSpoken', 'state']\n",
        "df_test = df_test.drop(columns=[col for col in drop_columns if col in df_test.columns])\n",
        "\n",
        "# Ensure test data has same features as training\n",
        "for feature in train_feature_names:\n",
        "    if feature not in df_test.columns:\n",
        "        df_test[feature] = 0  # Add missing feature with default value\n",
        "\n",
        "# Reorder columns to match training\n",
        "df_test = df_test[train_feature_names]\n",
        "\n",
        "# ==============================\n",
        "# 3️⃣ Scale and Reshape Test Data\n",
        "# ==============================\n",
        "X_test_new = scaler.transform(df_test)  # Scale using the same scaler\n",
        "X_test_reshaped_new = X_test_new.reshape(X_test_new.shape[0], 1, X_test_new.shape[1])\n",
        "\n",
        "# ==============================\n",
        "# 4️⃣ Make Predictions\n",
        "# ==============================\n",
        "predictions = model.predict(X_test_reshaped_new)\n",
        "predicted_class_indices = np.argmax(predictions, axis=1)\n",
        "predicted_labels = language_encoder.inverse_transform(predicted_class_indices)\n",
        "\n",
        "# ==============================\n",
        "# 5️⃣ Print Predictions vs Actual Labels\n",
        "# ==============================\n",
        "print(\"\\n🎯 Model Predictions vs Actual Labels:\")\n",
        "print(f\"{'Sample':<10}{'Actual':<20}{'Predicted':<20}\")\n",
        "\n",
        "for i, (actual, predicted) in enumerate(zip(actual_languages, predicted_labels)):\n",
        "    print(f\"{i+1:<10}{actual:<20}{predicted:<20}\")\n",
        "\n",
        "# ==============================\n",
        "# 6️⃣ Compute Accuracy\n",
        "# ==============================\n",
        "y_test_encoded = language_encoder.transform(actual_languages)\n",
        "correct_predictions = sum(np.array(predicted_labels) == np.array(actual_languages))\n",
        "accuracy = correct_predictions / len(actual_languages)\n",
        "\n",
        "print(f\"\\n✅ Final Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "EPSpai7VamWA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "e0ddc275-2b26-4059-a577-438f8dd53023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/content/drive/MyDrive/IE3 Lab/Sakshi PC/Vaani MHA/final colab.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0cab7afd404c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Load Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Model loaded successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 564\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/content/drive/MyDrive/IE3 Lab/Sakshi PC/Vaani MHA/final colab.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hybrid Language model (BiLSTM +MHA)"
      ],
      "metadata": {
        "id": "1P4_KxnGfTPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2Ep_SaNa32V",
        "outputId": "5cc0187f-1003-4401-a1dd-5ad3a481e247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, Dropout, Input, MultiHeadAttention, LayerNormalization, Flatten, LSTM, Bidirectional\n",
        ")\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# ==============================\n",
        "# 1️⃣ Load Training Data\n",
        "# ==============================\n",
        "csv_file_path =\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/merged_data.csv\"\n",
        "df = pd.read_csv(csv_file_path)\n",
        "print(\"✅ Loaded training data!\")\n",
        "\n",
        "# ==============================\n",
        "# 2️⃣ Preprocess Data\n",
        "# ==============================\n",
        "X = df.drop(columns=['id', 'filename', 'file_url', 'gender', 'pincode', 'district',\n",
        "                     'stayYears', 'assertLanguage', 'languagesSpoken', 'state'], errors='ignore')\n",
        "y = df['assertLanguage']\n",
        "\n",
        "# Encode labels\n",
        "language_encoder = LabelEncoder()\n",
        "y = language_encoder.fit_transform(y)\n",
        "\n",
        "# Save Label Encoder\n",
        "joblib.dump(language_encoder, \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/language_encoder.pkl\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
        "\n",
        "# Save training feature names\n",
        "train_feature_names = list(X_train.columns)\n",
        "joblib.dump(train_feature_names,  \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/train_feature_names.pkl\")\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Save Scaler\n",
        "joblib.dump(scaler,  \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/scaler.pkl\")\n",
        "\n",
        "# Reshape for Multi-Head Attention\n",
        "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
        "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train_categorical = to_categorical(y_train, num_classes=len(language_encoder.classes_))\n",
        "y_test_categorical = to_categorical(y_test, num_classes=len(language_encoder.classes_))\n",
        "\n",
        "print(\"✅ Preprocessing done!\")\n",
        "\n",
        "# ==============================\n",
        "# 3️⃣ Define Hybrid Multi-Head Attention + BiLSTM Model\n",
        "# ==============================\n",
        "input_layer = Input(shape=(1, X_train.shape[1]))\n",
        "\n",
        "# Multi-Head Attention Layer\n",
        "attention_output = MultiHeadAttention(num_heads=4, key_dim=32)(input_layer, input_layer)\n",
        "attention_output = LayerNormalization(epsilon=1e-6)(attention_output)\n",
        "\n",
        "# BiLSTM Layers for Sequential Learning\n",
        "bilstm_output = Bidirectional(LSTM(128, return_sequences=True))(attention_output)\n",
        "bilstm_output = Dropout(0.3)(bilstm_output)\n",
        "bilstm_output = Bidirectional(LSTM(64, return_sequences=False))(bilstm_output)\n",
        "bilstm_output = Dropout(0.3)(bilstm_output)\n",
        "\n",
        "# Fully Connected Layers\n",
        "x = Dense(64, activation='relu')(bilstm_output)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "output_layer = Dense(len(language_encoder.classes_), activation='softmax')(x)\n",
        "\n",
        "# Create Model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# ==============================\n",
        "# 4️⃣ Train the Model\n",
        "# ==============================\n",
        "history = model.fit(\n",
        "    X_train_reshaped, y_train_categorical,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_reshaped, y_test_categorical),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# 5️⃣ Save Model\n",
        "# ==============================\n",
        "model.save( \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/Final code.h5\")\n",
        "print(\"✅ Hybrid Model training complete and saved!\")\n"
      ],
      "metadata": {
        "id": "IzNhRsOyamcZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "be278428-e146-43d8-e702-f64ece071ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded training data!\n",
            "✅ Preprocessing done!\n",
            "Epoch 1/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 16ms/step - accuracy: 0.4775 - loss: 1.7455 - val_accuracy: 0.6035 - val_loss: 1.2304\n",
            "Epoch 2/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 16ms/step - accuracy: 0.6005 - loss: 1.2564 - val_accuracy: 0.6621 - val_loss: 1.0396\n",
            "Epoch 3/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - accuracy: 0.6497 - loss: 1.0969 - val_accuracy: 0.7015 - val_loss: 0.9151\n",
            "Epoch 4/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.6884 - loss: 0.9718 - val_accuracy: 0.7267 - val_loss: 0.8367\n",
            "Epoch 5/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.7105 - loss: 0.9069 - val_accuracy: 0.7480 - val_loss: 0.7763\n",
            "Epoch 6/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.7320 - loss: 0.8342 - val_accuracy: 0.7659 - val_loss: 0.7256\n",
            "Epoch 7/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - accuracy: 0.7432 - loss: 0.7986 - val_accuracy: 0.7756 - val_loss: 0.6928\n",
            "Epoch 8/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.7599 - loss: 0.7493 - val_accuracy: 0.7870 - val_loss: 0.6676\n",
            "Epoch 9/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - accuracy: 0.7640 - loss: 0.7286 - val_accuracy: 0.7919 - val_loss: 0.6480\n",
            "Epoch 10/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.7771 - loss: 0.6972 - val_accuracy: 0.7968 - val_loss: 0.6349\n",
            "Epoch 11/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.7823 - loss: 0.6742 - val_accuracy: 0.8043 - val_loss: 0.6162\n",
            "Epoch 12/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.7895 - loss: 0.6515 - val_accuracy: 0.8074 - val_loss: 0.5994\n",
            "Epoch 13/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.7953 - loss: 0.6339 - val_accuracy: 0.8130 - val_loss: 0.5902\n",
            "Epoch 14/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8005 - loss: 0.6159 - val_accuracy: 0.8143 - val_loss: 0.5901\n",
            "Epoch 15/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.8109 - loss: 0.5918 - val_accuracy: 0.8200 - val_loss: 0.5701\n",
            "Epoch 16/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - accuracy: 0.8108 - loss: 0.5902 - val_accuracy: 0.8171 - val_loss: 0.5749\n",
            "Epoch 17/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8119 - loss: 0.5847 - val_accuracy: 0.8225 - val_loss: 0.5570\n",
            "Epoch 18/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.8177 - loss: 0.5610 - val_accuracy: 0.8259 - val_loss: 0.5487\n",
            "Epoch 19/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - accuracy: 0.8233 - loss: 0.5436 - val_accuracy: 0.8228 - val_loss: 0.5581\n",
            "Epoch 20/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.8225 - loss: 0.5536 - val_accuracy: 0.8270 - val_loss: 0.5401\n",
            "Epoch 21/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8275 - loss: 0.5241 - val_accuracy: 0.8291 - val_loss: 0.5409\n",
            "Epoch 22/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8302 - loss: 0.5168 - val_accuracy: 0.8297 - val_loss: 0.5364\n",
            "Epoch 23/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8329 - loss: 0.5127 - val_accuracy: 0.8305 - val_loss: 0.5360\n",
            "Epoch 24/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8354 - loss: 0.5011 - val_accuracy: 0.8331 - val_loss: 0.5279\n",
            "Epoch 25/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8397 - loss: 0.4957 - val_accuracy: 0.8322 - val_loss: 0.5332\n",
            "Epoch 26/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8394 - loss: 0.4907 - val_accuracy: 0.8318 - val_loss: 0.5365\n",
            "Epoch 27/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8399 - loss: 0.4889 - val_accuracy: 0.8350 - val_loss: 0.5248\n",
            "Epoch 28/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8468 - loss: 0.4731 - val_accuracy: 0.8348 - val_loss: 0.5217\n",
            "Epoch 29/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.8485 - loss: 0.4630 - val_accuracy: 0.8343 - val_loss: 0.5270\n",
            "Epoch 30/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - accuracy: 0.8479 - loss: 0.4666 - val_accuracy: 0.8370 - val_loss: 0.5255\n",
            "Epoch 31/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8498 - loss: 0.4650 - val_accuracy: 0.8402 - val_loss: 0.5114\n",
            "Epoch 32/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8473 - loss: 0.4582 - val_accuracy: 0.8376 - val_loss: 0.5244\n",
            "Epoch 33/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8510 - loss: 0.4545 - val_accuracy: 0.8384 - val_loss: 0.5219\n",
            "Epoch 34/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - accuracy: 0.8554 - loss: 0.4415 - val_accuracy: 0.8363 - val_loss: 0.5211\n",
            "Epoch 35/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8521 - loss: 0.4417 - val_accuracy: 0.8390 - val_loss: 0.5188\n",
            "Epoch 36/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.8567 - loss: 0.4356 - val_accuracy: 0.8427 - val_loss: 0.5075\n",
            "Epoch 37/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8595 - loss: 0.4298 - val_accuracy: 0.8415 - val_loss: 0.5108\n",
            "Epoch 38/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8590 - loss: 0.4255 - val_accuracy: 0.8405 - val_loss: 0.5127\n",
            "Epoch 39/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8617 - loss: 0.4214 - val_accuracy: 0.8402 - val_loss: 0.5127\n",
            "Epoch 40/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.8578 - loss: 0.4291 - val_accuracy: 0.8419 - val_loss: 0.5049\n",
            "Epoch 41/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 17ms/step - accuracy: 0.8621 - loss: 0.4146 - val_accuracy: 0.8432 - val_loss: 0.5030\n",
            "Epoch 42/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8620 - loss: 0.4140 - val_accuracy: 0.8406 - val_loss: 0.5140\n",
            "Epoch 43/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8620 - loss: 0.4195 - val_accuracy: 0.8432 - val_loss: 0.5084\n",
            "Epoch 44/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8641 - loss: 0.4100 - val_accuracy: 0.8391 - val_loss: 0.5102\n",
            "Epoch 45/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8659 - loss: 0.4077 - val_accuracy: 0.8443 - val_loss: 0.5072\n",
            "Epoch 46/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8675 - loss: 0.4047 - val_accuracy: 0.8445 - val_loss: 0.5056\n",
            "Epoch 47/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8680 - loss: 0.4069 - val_accuracy: 0.8424 - val_loss: 0.5148\n",
            "Epoch 48/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.8636 - loss: 0.4099 - val_accuracy: 0.8442 - val_loss: 0.5066\n",
            "Epoch 49/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8673 - loss: 0.4018 - val_accuracy: 0.8422 - val_loss: 0.5163\n",
            "Epoch 50/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.8709 - loss: 0.3953 - val_accuracy: 0.8434 - val_loss: 0.5074\n",
            "Epoch 51/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8722 - loss: 0.3839 - val_accuracy: 0.8439 - val_loss: 0.5132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Hybrid Model training complete and saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# ==============================\n",
        "# 1️⃣ Load Saved Model & Encoders\n",
        "# ==============================\n",
        "model_path =  \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/Final code.h5\"\n",
        "encoder_path = \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/language_encoder.pkl\"\n",
        "scaler_path =  \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/scaler.pkl\"\n",
        "feature_names_path =  \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/train_feature_names.pkl\"\n",
        "\n",
        "# Load Model\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "print(\"✅ Model loaded successfully!\")\n",
        "\n",
        "# Load Label Encoder\n",
        "if os.path.exists(encoder_path):\n",
        "    language_encoder = joblib.load(encoder_path)\n",
        "else:\n",
        "    raise FileNotFoundError(\"🚨 Label Encoder file not found. Run training script first.\")\n",
        "\n",
        "# Load Scaler\n",
        "if os.path.exists(scaler_path):\n",
        "    scaler = joblib.load(scaler_path)\n",
        "else:\n",
        "    raise FileNotFoundError(\"🚨 Scaler file not found. Run training script first.\")\n",
        "\n",
        "# Load Training Feature Names\n",
        "if os.path.exists(feature_names_path):\n",
        "    train_feature_names = joblib.load(feature_names_path)\n",
        "else:\n",
        "    raise FileNotFoundError(\"🚨 Training feature names file not found. Run training script first.\")\n",
        "\n",
        "# ==============================\n",
        "# 2️⃣ Load and Process Test Data\n",
        "# ==============================\n",
        "test_csv_path = \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/test_audio_final.csv\"\n",
        "df_test = pd.read_csv(test_csv_path)\n",
        "\n",
        "# Extract actual labels before dropping columns\n",
        "actual_languages = df_test['assertLanguage'].tolist()  # Store actual languages\n",
        "\n",
        "# Drop unnecessary columns\n",
        "drop_columns = ['id', 'filename', 'file_url', 'gender', 'pincode', 'district',\n",
        "                'stayYears', 'assertLanguage', 'languagesSpoken', 'state']\n",
        "df_test = df_test.drop(columns=[col for col in drop_columns if col in df_test.columns])\n",
        "\n",
        "# Ensure test data has same features as training\n",
        "for feature in train_feature_names:\n",
        "    if feature not in df_test.columns:\n",
        "        df_test[feature] = 0  # Add missing feature with default value\n",
        "\n",
        "# Reorder columns to match training\n",
        "df_test = df_test[train_feature_names]\n",
        "\n",
        "# ==============================\n",
        "# 3️⃣ Scale and Reshape Test Data\n",
        "# ==============================\n",
        "X_test_new = scaler.transform(df_test)  # Scale using the same scaler\n",
        "X_test_reshaped_new = X_test_new.reshape(X_test_new.shape[0], 1, X_test_new.shape[1])\n",
        "\n",
        "# ==============================\n",
        "# 4️⃣ Make Predictions\n",
        "# ==============================\n",
        "predictions = model.predict(X_test_reshaped_new)\n",
        "predicted_class_indices = np.argmax(predictions, axis=1)\n",
        "predicted_labels = language_encoder.inverse_transform(predicted_class_indices)\n",
        "\n",
        "# ==============================\n",
        "# 5️⃣ Print Predictions vs Actual Labels\n",
        "# ==============================\n",
        "print(\"\\n🎯 Model Predictions vs Actual Labels:\")\n",
        "print(f\"{'Sample':<10}{'Actual':<20}{'Predicted':<20}\")\n",
        "\n",
        "for i, (actual, predicted) in enumerate(zip(actual_languages, predicted_labels)):\n",
        "    print(f\"{i+1:<10}{actual:<20}{predicted:<20}\")\n",
        "\n",
        "# ==============================\n",
        "# 6️⃣ Compute Accuracy\n",
        "# ==============================\n",
        "y_test_encoded = language_encoder.transform(actual_languages)\n",
        "correct_predictions = sum(np.array(predicted_labels) == np.array(actual_languages))\n",
        "accuracy = correct_predictions / len(actual_languages)\n",
        "\n",
        "print(f\"\\n✅ Final Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "m1lxl5NtamgC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "236cbaed-89a4-451e-d346-56944f7ce21d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded successfully!\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713ms/step\n",
            "\n",
            "🎯 Model Predictions vs Actual Labels:\n",
            "Sample    Actual              Predicted           \n",
            "1         HINDI               HINDI               \n",
            "2         HINDI               HINDI               \n",
            "3         HINDI               HINDI               \n",
            "4         HINDI               HINDI               \n",
            "5         HINDI               HINDI               \n",
            "6         HINDI               HINDI               \n",
            "7         MARWARI             RAJASTHANI          \n",
            "8         RAJASTHANI          RAJASTHANI          \n",
            "9         MARWARI             RAJASTHANI          \n",
            "10        MARWARI             RAJASTHANI          \n",
            "11        RAJASTHANI          RAJASTHANI          \n",
            "12        HINDI               HINDI               \n",
            "13        HINDI               HINDI               \n",
            "14        HINDI               HINDI               \n",
            "15        HINDI               HINDI               \n",
            "16        HINDI               HINDI               \n",
            "17        HINDI               HINDI               \n",
            "18        HINDI               HINDI               \n",
            "19        HINDI               HINDI               \n",
            "20        HINDI               HINDI               \n",
            "21        MARATHI             MARATHI             \n",
            "22        HINDI               CHATTISGARHI        \n",
            "23        KONKANI             TELUGU              \n",
            "24        KONKANI             KONKANI             \n",
            "25        HINDI               TELUGU              \n",
            "26        HINDI               HINDI               \n",
            "27        HINDI               TELUGU              \n",
            "28        HINDI               URDU                \n",
            "29        HINDI               HINDI               \n",
            "30        HINDI               TELUGU              \n",
            "31        HINDI               TELUGU              \n",
            "32        HINDI               RAJASTHANI          \n",
            "33        HINDI               HINDI               \n",
            "34        HINDI               MARWARI             \n",
            "35        HINDI               RAJASTHANI          \n",
            "36        HINDI               HINDI               \n",
            "37        HINDI               HINDI               \n",
            "38        HINDI               HINDI               \n",
            "39        HINDI               HINDI               \n",
            "40        HINDI               HINDI               \n",
            "41        HINDI               HINDI               \n",
            "42        HINDI               HINDI               \n",
            "43        HINDI               HINDI               \n",
            "44        HINDI               HINDI               \n",
            "45        HINDI               HINDI               \n",
            "\n",
            "✅ Final Test Accuracy: 0.7111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MHA+BILSTM+CNN\n"
      ],
      "metadata": {
        "id": "w1ENbiCKmGTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, Dropout, Input, MultiHeadAttention, LayerNormalization,\n",
        "    Conv1D, MaxPooling1D, Flatten, LSTM, Bidirectional\n",
        ")\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# ==============================\n",
        "# 1️⃣ Load Training Data\n",
        "# ==============================\n",
        "csv_file_path =\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/merged_data.csv\"\n",
        "df = pd.read_csv(csv_file_path)\n",
        "print(\"✅ Loaded training data!\")\n",
        "\n",
        "# ==============================\n",
        "# 2️⃣ Preprocess Data\n",
        "# ==============================\n",
        "X = df.drop(columns=['id', 'filename', 'file_url', 'gender', 'pincode', 'district',\n",
        "                     'stayYears', 'assertLanguage', 'languagesSpoken', 'state'], errors='ignore')\n",
        "y = df['assertLanguage']\n",
        "\n",
        "# Encode labels\n",
        "language_encoder = LabelEncoder()\n",
        "y = language_encoder.fit_transform(y)\n",
        "\n",
        "# Save Label Encoder\n",
        "joblib.dump(language_encoder, \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/language_encoder.pkl\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
        "\n",
        "# Save training feature names\n",
        "train_feature_names = list(X_train.columns)\n",
        "joblib.dump(train_feature_names,  \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/train_feature_names.pkl\")\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Save Scaler\n",
        "joblib.dump(scaler,  \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/scaler.pkl\")\n",
        "\n",
        "# Reshape for Conv1D and MHA (sequence_length > 1 for CNN)\n",
        "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
        "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train_categorical = to_categorical(y_train, num_classes=len(language_encoder.classes_))\n",
        "y_test_categorical = to_categorical(y_test, num_classes=len(language_encoder.classes_))\n",
        "\n",
        "print(\"✅ Preprocessing done!\")\n",
        "\n",
        "# ==============================\n",
        "# 3️⃣ Define CNN + BiLSTM + MHA Model\n",
        "# ==============================\n",
        "input_layer = Input(shape=(X_train.shape[1], 1))  # (timesteps, features)\n",
        "\n",
        "# 1D Convolution Layer\n",
        "cnn_output = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "cnn_output = MaxPooling1D(pool_size=2)(cnn_output)\n",
        "\n",
        "# Multi-Head Attention Layer\n",
        "attention_output = MultiHeadAttention(num_heads=4, key_dim=32)(cnn_output, cnn_output)\n",
        "attention_output = LayerNormalization(epsilon=1e-6)(attention_output)\n",
        "\n",
        "# BiLSTM Layers for Sequential Learning\n",
        "bilstm_output = Bidirectional(LSTM(128, return_sequences=True))(attention_output)\n",
        "bilstm_output = Dropout(0.3)(bilstm_output)\n",
        "bilstm_output = Bidirectional(LSTM(64, return_sequences=False))(bilstm_output)\n",
        "bilstm_output = Dropout(0.3)(bilstm_output)\n",
        "\n",
        "# Fully Connected Layers\n",
        "x = Dense(64, activation='relu')(bilstm_output)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "output_layer = Dense(len(language_encoder.classes_), activation='softmax')(x)\n",
        "\n",
        "# Create Model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# ==============================\n",
        "# 4️⃣ Train the Model\n",
        "# ==============================\n",
        "history = model.fit(\n",
        "    X_train_reshaped, y_train_categorical,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_reshaped, y_test_categorical),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# 5️⃣ Save Model\n",
        "# ==============================\n",
        "model.save(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/Final_CNN_BiLSTM_MHA_Model.h5\")\n",
        "print(\"✅ CNN + BiLSTM + MHA Model training complete and saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0oJUD-d3mI5k",
        "outputId": "2b8e0c07-2b1a-4d3a-977a-c237821a89dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded training data!\n",
            "✅ Preprocessing done!\n",
            "Epoch 1/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - accuracy: 0.4334 - loss: 1.9292 - val_accuracy: 0.4569 - val_loss: 1.7079\n",
            "Epoch 2/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.4596 - loss: 1.7047 - val_accuracy: 0.4942 - val_loss: 1.5903\n",
            "Epoch 3/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 18ms/step - accuracy: 0.4995 - loss: 1.5900 - val_accuracy: 0.5430 - val_loss: 1.4564\n",
            "Epoch 4/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 22ms/step - accuracy: 0.5329 - loss: 1.4952 - val_accuracy: 0.5620 - val_loss: 1.3790\n",
            "Epoch 5/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 19ms/step - accuracy: 0.5574 - loss: 1.4090 - val_accuracy: 0.5916 - val_loss: 1.2783\n",
            "Epoch 6/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.5847 - loss: 1.3179 - val_accuracy: 0.6081 - val_loss: 1.2210\n",
            "Epoch 7/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.6037 - loss: 1.2461 - val_accuracy: 0.6245 - val_loss: 1.1727\n",
            "Epoch 8/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 22ms/step - accuracy: 0.6237 - loss: 1.1823 - val_accuracy: 0.6389 - val_loss: 1.1306\n",
            "Epoch 9/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 19ms/step - accuracy: 0.6392 - loss: 1.1318 - val_accuracy: 0.6490 - val_loss: 1.0938\n",
            "Epoch 10/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.6513 - loss: 1.0926 - val_accuracy: 0.6569 - val_loss: 1.0732\n",
            "Epoch 11/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.6692 - loss: 1.0359 - val_accuracy: 0.6624 - val_loss: 1.0681\n",
            "Epoch 12/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.6851 - loss: 0.9964 - val_accuracy: 0.6742 - val_loss: 1.0269\n",
            "Epoch 13/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.7023 - loss: 0.9501 - val_accuracy: 0.6809 - val_loss: 1.0140\n",
            "Epoch 14/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 19ms/step - accuracy: 0.7085 - loss: 0.9184 - val_accuracy: 0.6824 - val_loss: 1.0078\n",
            "Epoch 15/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.7179 - loss: 0.8891 - val_accuracy: 0.6921 - val_loss: 0.9914\n",
            "Epoch 16/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 22ms/step - accuracy: 0.7276 - loss: 0.8626 - val_accuracy: 0.6932 - val_loss: 0.9794\n",
            "Epoch 17/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 23ms/step - accuracy: 0.7379 - loss: 0.8260 - val_accuracy: 0.6981 - val_loss: 0.9731\n",
            "Epoch 18/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 19ms/step - accuracy: 0.7524 - loss: 0.7873 - val_accuracy: 0.6935 - val_loss: 1.0016\n",
            "Epoch 19/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 30ms/step - accuracy: 0.7549 - loss: 0.7668 - val_accuracy: 0.7047 - val_loss: 0.9717\n",
            "Epoch 20/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 22ms/step - accuracy: 0.7574 - loss: 0.7529 - val_accuracy: 0.7002 - val_loss: 0.9824\n",
            "Epoch 21/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 20ms/step - accuracy: 0.7684 - loss: 0.7223 - val_accuracy: 0.7069 - val_loss: 0.9408\n",
            "Epoch 22/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.7750 - loss: 0.7027 - val_accuracy: 0.7030 - val_loss: 0.9720\n",
            "Epoch 23/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 23ms/step - accuracy: 0.7824 - loss: 0.6814 - val_accuracy: 0.7113 - val_loss: 0.9704\n",
            "Epoch 24/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.7888 - loss: 0.6605 - val_accuracy: 0.7121 - val_loss: 0.9688\n",
            "Epoch 25/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 19ms/step - accuracy: 0.7929 - loss: 0.6466 - val_accuracy: 0.7091 - val_loss: 0.9926\n",
            "Epoch 26/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8032 - loss: 0.6189 - val_accuracy: 0.7041 - val_loss: 0.9891\n",
            "Epoch 27/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.8046 - loss: 0.6142 - val_accuracy: 0.7079 - val_loss: 0.9768\n",
            "Epoch 28/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - accuracy: 0.8092 - loss: 0.5931 - val_accuracy: 0.7132 - val_loss: 0.9985\n",
            "Epoch 29/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.8178 - loss: 0.5739 - val_accuracy: 0.7128 - val_loss: 0.9875\n",
            "Epoch 30/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8237 - loss: 0.5556 - val_accuracy: 0.7132 - val_loss: 1.0006\n",
            "Epoch 31/100\n",
            "\u001b[1m1388/1388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8221 - loss: 0.5597 - val_accuracy: 0.7143 - val_loss: 1.0159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CNN + BiLSTM + MHA Model training complete and saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# ==============================\n",
        "# 1️⃣ Load Saved Model & Encoders\n",
        "# ==============================\n",
        "model_path =  \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/Final_CNN_BiLSTM_MHA_Model.h5\"\n",
        "encoder_path = \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/language_encoder.pkl\"\n",
        "scaler_path =  \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/scaler.pkl\"\n",
        "feature_names_path =  \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/train_feature_names.pkl\"\n",
        "\n",
        "# Load model and preprocessing tools\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "language_encoder = joblib.load(encoder_path)\n",
        "scaler = joblib.load(scaler_path)\n",
        "train_feature_names = joblib.load(feature_names_path)\n",
        "\n",
        "print(\"✅ Model and encoders loaded successfully!\")\n",
        "\n",
        "# ==============================\n",
        "# 2️⃣ Load and Process Test Data\n",
        "# ==============================\n",
        "test_csv_path = \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/test_audio_final.csv\"\n",
        "df_test = pd.read_csv(test_csv_path)\n",
        "\n",
        "# Extract ground truth\n",
        "actual_languages = df_test['assertLanguage'].tolist()\n",
        "\n",
        "# Drop unused columns\n",
        "drop_columns = ['id', 'filename', 'file_url', 'gender', 'pincode', 'district',\n",
        "                'stayYears', 'assertLanguage', 'languagesSpoken', 'state']\n",
        "df_test = df_test.drop(columns=[col for col in drop_columns if col in df_test.columns])\n",
        "\n",
        "# Ensure matching features\n",
        "for feature in train_feature_names:\n",
        "    if feature not in df_test.columns:\n",
        "        df_test[feature] = 0\n",
        "\n",
        "# Match order\n",
        "df_test = df_test[train_feature_names]\n",
        "\n",
        "# ==============================\n",
        "# 3️⃣ Scale & Reshape for CNN + BiLSTM + MHA\n",
        "# ==============================\n",
        "X_test_scaled = scaler.transform(df_test)\n",
        "\n",
        "# ✅ Reshape: (batch, time_steps=features, channels=1)\n",
        "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
        "\n",
        "# ==============================\n",
        "# 4️⃣ Predict\n",
        "# ==============================\n",
        "predictions = model.predict(X_test_reshaped)\n",
        "predicted_class_indices = np.argmax(predictions, axis=1)\n",
        "predicted_labels = language_encoder.inverse_transform(predicted_class_indices)\n",
        "\n",
        "# ==============================\n",
        "# 5️⃣ Display Results\n",
        "# ==============================\n",
        "print(\"\\n🎯 Model Predictions vs Actual Labels:\")\n",
        "print(f\"{'Sample':<10}{'Actual':<20}{'Predicted':<20}\")\n",
        "\n",
        "for i, (actual, predicted) in enumerate(zip(actual_languages, predicted_labels)):\n",
        "    print(f\"{i+1:<10}{actual:<20}{predicted:<20}\")\n",
        "\n",
        "# ==============================\n",
        "# 6️⃣ Accuracy\n",
        "# ==============================\n",
        "correct_predictions = sum(np.array(predicted_labels) == np.array(actual_languages))\n",
        "accuracy = correct_predictions / len(actual_languages)\n",
        "print(f\"\\n✅ Final Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e7kkV0U2o8B7",
        "outputId": "279bef4e-8e11-4cc7-e958-243505ff7c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model and encoders loaded successfully!\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607ms/step\n",
            "\n",
            "🎯 Model Predictions vs Actual Labels:\n",
            "Sample    Actual              Predicted           \n",
            "1         HINDI               HINDI               \n",
            "2         HINDI               HINDI               \n",
            "3         HINDI               HINDI               \n",
            "4         HINDI               HINDI               \n",
            "5         HINDI               HINDI               \n",
            "6         HINDI               HINDI               \n",
            "7         MARWARI             RAJASTHANI          \n",
            "8         RAJASTHANI          RAJASTHANI          \n",
            "9         MARWARI             RAJASTHANI          \n",
            "10        MARWARI             RAJASTHANI          \n",
            "11        RAJASTHANI          RAJASTHANI          \n",
            "12        HINDI               HINDI               \n",
            "13        HINDI               HINDI               \n",
            "14        HINDI               HINDI               \n",
            "15        HINDI               HINDI               \n",
            "16        HINDI               HINDI               \n",
            "17        HINDI               HINDI               \n",
            "18        HINDI               HINDI               \n",
            "19        HINDI               HINDI               \n",
            "20        HINDI               HINDI               \n",
            "21        MARATHI             HINDI               \n",
            "22        HINDI               HINDI               \n",
            "23        KONKANI             KONKANI             \n",
            "24        KONKANI             KANNADA             \n",
            "25        HINDI               KANNADA             \n",
            "26        HINDI               TELUGU              \n",
            "27        HINDI               HINDI               \n",
            "28        HINDI               HINDI               \n",
            "29        HINDI               KANNADA             \n",
            "30        HINDI               TELUGU              \n",
            "31        HINDI               HINDI               \n",
            "32        HINDI               RAJASTHANI          \n",
            "33        HINDI               HINDI               \n",
            "34        HINDI               MARWARI             \n",
            "35        HINDI               TELUGU              \n",
            "36        HINDI               HINDI               \n",
            "37        HINDI               HINDI               \n",
            "38        HINDI               HINDI               \n",
            "39        HINDI               TELUGU              \n",
            "40        HINDI               HINDI               \n",
            "41        HINDI               HINDI               \n",
            "42        HINDI               HINDI               \n",
            "43        HINDI               HINDI               \n",
            "44        HINDI               HINDI               \n",
            "45        HINDI               HINDI               \n",
            "\n",
            "✅ Final Test Accuracy: 0.7111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensembeled Model\n"
      ],
      "metadata": {
        "id": "kUiMGg1C54dI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# ========================\n",
        "# 1️⃣ Load the CSV\n",
        "# ========================\n",
        "csv_file_path = \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/merged_data.csv\"\n",
        "df = pd.read_csv(csv_file_path)\n",
        "print(\"✅ Loaded Data!\")\n",
        "\n",
        "# ========================\n",
        "# 2️⃣ Preprocessing\n",
        "# ========================\n",
        "X = df.drop(columns=['id', 'filename', 'file_url', 'gender', 'pincode', 'district',\n",
        "                     'stayYears', 'assertLanguage', 'languagesSpoken', 'state'], errors='ignore')\n",
        "y = df['assertLanguage']\n",
        "\n",
        "# Label encoding\n",
        "language_encoder = joblib.load(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/language_encoder.pkl\")\n",
        "y_encoded = language_encoder.transform(y)\n",
        "\n",
        "# Load scaler\n",
        "scaler = joblib.load(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/scaler.pkl\")\n",
        "X_scaled = scaler.transform(X)\n",
        "\n",
        "# Reshape for each model\n",
        "X_mha = X_scaled.reshape(X_scaled.shape[0], 1, X_scaled.shape[1])               # MHA & MHA+BiLSTM\n",
        "X_cnn = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)              # CNN+BiLSTM+MHA\n",
        "\n",
        "# ========================\n",
        "# 3️⃣ Load Models\n",
        "# ========================\n",
        "model_mha = load_model(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/Vaani MHA/final colab.h5\")\n",
        "model_bilstm_mha = load_model(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/Final code.h5\")\n",
        "model_cnn_bilstm_mha = load_model(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/Final_CNN_BiLSTM_MHA_Model.h5\")\n",
        "\n",
        "print(\"✅ Models loaded!\")\n",
        "\n",
        "# ========================\n",
        "# 4️⃣ Get Predictions\n",
        "# ========================\n",
        "pred_mha = model_mha.predict(X_mha)\n",
        "pred_bilstm_mha = model_bilstm_mha.predict(X_mha)\n",
        "pred_cnn_bilstm_mha = model_cnn_bilstm_mha.predict(X_cnn)\n",
        "\n",
        "# Concatenate predictions for meta model\n",
        "ensemble_input = np.concatenate([pred_mha, pred_bilstm_mha, pred_cnn_bilstm_mha], axis=1)\n",
        "\n",
        "# ========================\n",
        "# 5️⃣ Train RandomForest on these predictions\n",
        "# ========================\n",
        "meta_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "meta_model.fit(ensemble_input, y_encoded)\n",
        "ensemble_preds = meta_model.predict(ensemble_input)\n",
        "\n",
        "# ========================\n",
        "# 6️⃣ Evaluation\n",
        "# ========================\n",
        "print(\"✅ Ensemble Model Performance:\")\n",
        "print(classification_report(y_encoded, ensemble_preds, target_names=language_encoder.classes_))\n",
        "print(\"🎯 Accuracy:\", accuracy_score(y_encoded, ensemble_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuB16VR957hV",
        "outputId": "67845190-0bd8-4e6c-aec2-f07cea9d3e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded Data!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Models loaded!\n",
            "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
            "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step\n",
            "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step\n",
            "✅ Ensemble Model Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     BENGALI       1.00      1.00      1.00      1510\n",
            "      BHATRI       1.00      1.00      1.00        88\n",
            "CHATTISGARHI       1.00      1.00      1.00      1788\n",
            "       GONDI       1.00      1.00      1.00         2\n",
            "       HALBI       1.00      1.00      1.00      1163\n",
            "       HINDI       1.00      1.00      1.00     32397\n",
            "     KANNADA       1.00      1.00      1.00      6066\n",
            "     KHORTHA       1.00      1.00      1.00      1442\n",
            "     KONKANI       1.00      1.00      1.00      1263\n",
            "    MAITHILI       1.00      1.00      1.00      1289\n",
            "     MARATHI       1.00      1.00      1.00      4194\n",
            "     MARWARI       1.00      1.00      1.00      2614\n",
            "  RAJASTHANI       1.00      1.00      1.00      9872\n",
            "      TELUGU       1.00      1.00      1.00      9956\n",
            "        URDU       1.00      1.00      1.00       340\n",
            "\n",
            "    accuracy                           1.00     73984\n",
            "   macro avg       1.00      1.00      1.00     73984\n",
            "weighted avg       1.00      1.00      1.00     73984\n",
            "\n",
            "🎯 Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "\n",
        "# ============================================\n",
        "# 1️⃣ Load and Preprocess Full Dataset\n",
        "# ============================================\n",
        "csv_path = \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/merged_data.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Drop metadata columns, keep features and label\n",
        "X = df.drop(columns=['id', 'filename', 'file_url', 'gender', 'pincode', 'district',\n",
        "                     'stayYears', 'assertLanguage', 'languagesSpoken', 'state'], errors='ignore')\n",
        "y = df['assertLanguage']\n",
        "\n",
        "# Label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "joblib.dump(label_encoder, \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/label_encoder.pkl\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.4, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "joblib.dump(scaler, \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/scaler.pkl\")\n",
        "\n",
        "# Save X_test and y_test for ensemble use\n",
        "joblib.dump(X_test_scaled, \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/X_test_scaled.pkl\")\n",
        "joblib.dump(y_test, \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/y_test.pkl\")\n",
        "\n",
        "# ============================================\n",
        "# 2️⃣ Load Trained Deep Learning Models\n",
        "# ============================================\n",
        "model_mha = load_model(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/Vaani MHA/final colab.h5\")\n",
        "model_bilstm = load_model(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/Final code.h5\")\n",
        "model_cnn = load_model(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/Final_CNN_BiLSTM_MHA_Model.h5\")\n",
        "\n",
        "# ============================================\n",
        "# 3️⃣ Prepare Input Shapes for Each Model\n",
        "# ============================================\n",
        "X_mha = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
        "X_bilstm = X_mha\n",
        "X_cnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
        "\n",
        "# ============================================\n",
        "# 4️⃣ Generate Predictions from Each Model\n",
        "# ============================================\n",
        "pred_mha = model_mha.predict(X_mha)\n",
        "pred_bilstm = model_bilstm.predict(X_bilstm)\n",
        "pred_cnn = model_cnn.predict(X_cnn)\n",
        "\n",
        "# ============================================\n",
        "# 5️⃣ Train Random Forest Ensemble\n",
        "# ============================================\n",
        "ensemble_input = np.concatenate([pred_mha, pred_bilstm, pred_cnn], axis=1)\n",
        "rf_ensemble = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_ensemble.fit(ensemble_input, y_test)\n",
        "\n",
        "# ============================================\n",
        "# 6️⃣ Save Ensemble Model\n",
        "# ============================================\n",
        "joblib.dump(rf_ensemble, \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/ensemble_language_predictor.pkl\")\n",
        "\n",
        "print(\"✅ Ensemble model trained and saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu5Mxtde7ibo",
        "outputId": "bd729484-61b1-4715-9bd0-8896533876dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step\n",
            "\u001b[1m925/925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step\n",
            "✅ Ensemble model trained and saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# =====================================\n",
        "# 1️⃣ Load kabira.csv (only features)\n",
        "# =====================================\n",
        "kabira_df = pd.read_csv(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/skn csv features.csv\")\n",
        "\n",
        "# Rename columns to match original features (if needed)\n",
        "kabira_df.columns = [f\"feature_{i}\" for i in range(kabira_df.shape[1])]\n",
        "\n",
        "# =====================================\n",
        "# 2️⃣ Load Preprocessing Objects & Models\n",
        "# =====================================\n",
        "scaler = joblib.load(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/scaler.pkl\")\n",
        "label_encoder = joblib.load(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/label_encoder.pkl\")\n",
        "ensemble_model = joblib.load(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/ensemble_language_predictor.pkl\")\n",
        "\n",
        "model_mha = load_model(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/Vaani MHA/final colab.h5\")\n",
        "model_bilstm = load_model(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/Final code.h5\")\n",
        "model_cnn = load_model(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/Final_CNN_BiLSTM_MHA_Model.h5\")\n",
        "\n",
        "# =====================================\n",
        "# 3️⃣ Scale and Reshape Input\n",
        "# =====================================\n",
        "X_kabira_scaled = scaler.transform(kabira_df)\n",
        "\n",
        "X_kabira_mha = X_kabira_scaled.reshape(X_kabira_scaled.shape[0], 1, X_kabira_scaled.shape[1])\n",
        "X_kabira_bilstm = X_kabira_mha\n",
        "X_kabira_cnn = X_kabira_scaled.reshape(X_kabira_scaled.shape[0], X_kabira_scaled.shape[1], 1)\n",
        "\n",
        "# =====================================\n",
        "# 4️⃣ Get Predictions from All Models\n",
        "# =====================================\n",
        "pred_mha = model_mha.predict(X_kabira_mha)\n",
        "pred_bilstm = model_bilstm.predict(X_kabira_bilstm)\n",
        "pred_cnn = model_cnn.predict(X_kabira_cnn)\n",
        "\n",
        "# =====================================\n",
        "# 5️⃣ Ensemble Prediction\n",
        "# =====================================\n",
        "ensemble_input = np.concatenate([pred_mha, pred_bilstm, pred_cnn], axis=1)\n",
        "final_preds = ensemble_model.predict(ensemble_input)\n",
        "final_languages = label_encoder.inverse_transform(final_preds)\n",
        "\n",
        "# =====================================\n",
        "# 6️⃣ Output Results\n",
        "# =====================================\n",
        "for i, lang in enumerate(final_languages):\n",
        "    print(f\"🔤 Audio Sample {i+1}: Predicted Language → {lang}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSnNyndC85r0",
        "outputId": "6acdd3df-ed08-4ad8-bba5-5025e5f06c31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663ms/step\n",
            "🔤 Audio Sample 1: Predicted Language → HINDI\n",
            "🔤 Audio Sample 2: Predicted Language → TELUGU\n",
            "🔤 Audio Sample 3: Predicted Language → HINDI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# =====================================\n",
        "# 1️⃣ Load kabira.csv (only features)\n",
        "# =====================================\n",
        "kabira_df = pd.read_csv(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/kabira.csv\")\n",
        "\n",
        "# Rename columns to match original features (if needed)\n",
        "kabira_df.columns = [f\"feature_{i}\" for i in range(kabira_df.shape[1])]\n",
        "\n",
        "# =====================================\n",
        "# 2️⃣ Load Preprocessing Objects & Models\n",
        "# =====================================\n",
        "scaler = joblib.load(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/scaler.pkl\")\n",
        "label_encoder = joblib.load(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/label_encoder.pkl\")\n",
        "ensemble_model = joblib.load(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/ensemble_language_predictor.pkl\")\n",
        "\n",
        "model_mha = load_model(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/Vaani MHA/final colab.h5\")\n",
        "model_bilstm = load_model(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/Final code.h5\")\n",
        "model_cnn = load_model(\"/content/drive/MyDrive/IE3 Lab/Sakshi PC/VAANI BILSTM+MHA/Final_CNN_BiLSTM_MHA_Model.h5\")\n",
        "\n",
        "# =====================================\n",
        "# 3️⃣ Scale and Reshape Input\n",
        "# =====================================\n",
        "X_kabira_scaled = scaler.transform(kabira_df)\n",
        "\n",
        "X_kabira_mha = X_kabira_scaled.reshape(X_kabira_scaled.shape[0], 1, X_kabira_scaled.shape[1])\n",
        "X_kabira_bilstm = X_kabira_mha\n",
        "X_kabira_cnn = X_kabira_scaled.reshape(X_kabira_scaled.shape[0], X_kabira_scaled.shape[1], 1)\n",
        "\n",
        "# =====================================\n",
        "# 4️⃣ Get Predictions from All Models\n",
        "# =====================================\n",
        "pred_mha = model_mha.predict(X_kabira_mha)\n",
        "pred_bilstm = model_bilstm.predict(X_kabira_bilstm)\n",
        "pred_cnn = model_cnn.predict(X_kabira_cnn)\n",
        "\n",
        "# =====================================\n",
        "# 5️⃣ Ensemble Prediction\n",
        "# =====================================\n",
        "ensemble_input = np.concatenate([pred_mha, pred_bilstm, pred_cnn], axis=1)\n",
        "final_preds = ensemble_model.predict(ensemble_input)\n",
        "final_languages = label_encoder.inverse_transform(final_preds)\n",
        "\n",
        "# =====================================\n",
        "# 6️⃣ Output Results\n",
        "# =====================================\n",
        "for i, lang in enumerate(final_languages):\n",
        "    print(f\"🔤 Audio Sample {i+1}: Predicted Language → {lang}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCC8zair9kWK",
        "outputId": "d044a164-c3c7-4c06-b6ea-65c87809e29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step\n",
            "🔤 Audio Sample 1: Predicted Language → RAJASTHANI\n",
            "🔤 Audio Sample 2: Predicted Language → MARWARI\n",
            "🔤 Audio Sample 3: Predicted Language → BENGALI\n",
            "🔤 Audio Sample 4: Predicted Language → KANNADA\n",
            "🔤 Audio Sample 5: Predicted Language → URDU\n",
            "🔤 Audio Sample 6: Predicted Language → HINDI\n",
            "🔤 Audio Sample 7: Predicted Language → HALBI\n",
            "🔤 Audio Sample 8: Predicted Language → MARATHI\n",
            "🔤 Audio Sample 9: Predicted Language → KHORTHA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sakshi ends here"
      ],
      "metadata": {
        "id": "LWIPpuUtBBb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: mount google\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9PV8X0SiZ4o",
        "outputId": "510ea136-d31e-4516-c79b-41653bddf8f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, Conv1D, LSTM, Bidirectional, MultiHeadAttention, Flatten, LayerNormalization, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# ==============================\n",
        "# 1️⃣ Load Training Data\n",
        "# ==============================\n",
        "csv_file_path = \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/merged_data.csv\"\n",
        "df = pd.read_csv(csv_file_path)\n",
        "print(\"✅ Loaded training data!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y6luA8LhtpB",
        "outputId": "302a521c-8758-4ba9-c420-c35c30e397b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded training data!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbfAxsfIp2qX",
        "outputId": "a3daa9de-baff-4a17-a37c-4341b552680c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'filename', 'file_url', 'state', 'gender', 'pincode', 'district',\n",
              "       'stayYears', 'assertLanguage', 'languagesSpoken', 'feature_0',\n",
              "       'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5',\n",
              "       'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10',\n",
              "       'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15',\n",
              "       'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20',\n",
              "       'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25',\n",
              "       'feature_26', 'feature_27', 'feature_28', 'feature_29', 'feature_30',\n",
              "       'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_35',\n",
              "       'feature_36', 'feature_37'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sahitya=pd.read_csv(\"/content/drive/MyDrive/new test audios/Sahitya's Audio Features.csv\")\n",
        "nidhi=pd.read_csv(\"/content/drive/MyDrive/new test audios/Nidhi's Audio Features.csv\")\n",
        "kimaya=pd.read_csv(\"/content/drive/MyDrive/new test audios/Kimaya's Audio Features.csv\")"
      ],
      "metadata": {
        "id": "2kMeCpNPqWKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sahitya.columns = [f\"feature_{i}\" for i in range(len(sahitya.columns))]\n",
        "nidhi.columns = [f\"feature_{i}\" for i in range(len(nidhi.columns))]\n",
        "kimaya.columns = [f\"feature_{i}\" for i in range(len(kimaya.columns))]\n"
      ],
      "metadata": {
        "id": "9avNw8NsqjEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sahitya['assertLanguage'] = 'TELUGU'\n",
        "nidhi['assertLanguage'] = 'MARATHI'\n",
        "kimaya['assertLanguage'] = 'HINDI'\n",
        "import pandas as pd\n",
        "\n",
        "# Concatenating DataFrames\n",
        "combined_df = pd.concat([sahitya, nidhi, kimaya], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "adrKMsK8rcjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df=combined_df\n",
        "X_new=combined_df.drop(columns=['assertLanguage'])\n",
        "y_new=combined_df['assertLanguage']"
      ],
      "metadata": {
        "id": "1zLYu9yTr1qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "6prOJi2msVtr",
        "outputId": "74b1cc88-6e7c-404a-8cf4-44046a9d8938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
              "0 -301.82130  162.34149   3.773172  29.347368   5.833158  36.223263   \n",
              "1 -234.52022  143.98537 -16.144390   7.688753  -0.016806   6.717246   \n",
              "2 -318.37576  136.73366  20.810110  45.047370  -4.771094  27.556955   \n",
              "\n",
              "   feature_6  feature_7  feature_8  feature_9  ...  feature_29  feature_30  \\\n",
              "0 -13.055736   7.063834  -0.404653  -3.601685  ...   -1.981790   -2.183699   \n",
              "1 -24.379072   2.334164 -18.932920  -5.769550  ...    1.955276   -1.191994   \n",
              "2  -3.196370  15.037026   2.432315  -2.289925  ...    0.508572   -4.296451   \n",
              "\n",
              "   feature_31  feature_32  feature_33  feature_34  feature_35  feature_36  \\\n",
              "0   -1.061338    2.378047    1.560722    1.960453    2.480789    4.246184   \n",
              "1   -0.626358    2.216004    1.909258   -0.185616    0.284626    3.413281   \n",
              "2   -1.692242   -2.544844   -0.938026   -3.195067   -0.604838   -0.066298   \n",
              "\n",
              "   feature_37  assertLanguage  \n",
              "0    3.377369          TELUGU  \n",
              "1   -1.186310         MARATHI  \n",
              "2   -2.088836           HINDI  \n",
              "\n",
              "[3 rows x 39 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e676a0a-d042-47a6-b729-1e2669ab95f4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_29</th>\n",
              "      <th>feature_30</th>\n",
              "      <th>feature_31</th>\n",
              "      <th>feature_32</th>\n",
              "      <th>feature_33</th>\n",
              "      <th>feature_34</th>\n",
              "      <th>feature_35</th>\n",
              "      <th>feature_36</th>\n",
              "      <th>feature_37</th>\n",
              "      <th>assertLanguage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-301.82130</td>\n",
              "      <td>162.34149</td>\n",
              "      <td>3.773172</td>\n",
              "      <td>29.347368</td>\n",
              "      <td>5.833158</td>\n",
              "      <td>36.223263</td>\n",
              "      <td>-13.055736</td>\n",
              "      <td>7.063834</td>\n",
              "      <td>-0.404653</td>\n",
              "      <td>-3.601685</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.981790</td>\n",
              "      <td>-2.183699</td>\n",
              "      <td>-1.061338</td>\n",
              "      <td>2.378047</td>\n",
              "      <td>1.560722</td>\n",
              "      <td>1.960453</td>\n",
              "      <td>2.480789</td>\n",
              "      <td>4.246184</td>\n",
              "      <td>3.377369</td>\n",
              "      <td>TELUGU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-234.52022</td>\n",
              "      <td>143.98537</td>\n",
              "      <td>-16.144390</td>\n",
              "      <td>7.688753</td>\n",
              "      <td>-0.016806</td>\n",
              "      <td>6.717246</td>\n",
              "      <td>-24.379072</td>\n",
              "      <td>2.334164</td>\n",
              "      <td>-18.932920</td>\n",
              "      <td>-5.769550</td>\n",
              "      <td>...</td>\n",
              "      <td>1.955276</td>\n",
              "      <td>-1.191994</td>\n",
              "      <td>-0.626358</td>\n",
              "      <td>2.216004</td>\n",
              "      <td>1.909258</td>\n",
              "      <td>-0.185616</td>\n",
              "      <td>0.284626</td>\n",
              "      <td>3.413281</td>\n",
              "      <td>-1.186310</td>\n",
              "      <td>MARATHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-318.37576</td>\n",
              "      <td>136.73366</td>\n",
              "      <td>20.810110</td>\n",
              "      <td>45.047370</td>\n",
              "      <td>-4.771094</td>\n",
              "      <td>27.556955</td>\n",
              "      <td>-3.196370</td>\n",
              "      <td>15.037026</td>\n",
              "      <td>2.432315</td>\n",
              "      <td>-2.289925</td>\n",
              "      <td>...</td>\n",
              "      <td>0.508572</td>\n",
              "      <td>-4.296451</td>\n",
              "      <td>-1.692242</td>\n",
              "      <td>-2.544844</td>\n",
              "      <td>-0.938026</td>\n",
              "      <td>-3.195067</td>\n",
              "      <td>-0.604838</td>\n",
              "      <td>-0.066298</td>\n",
              "      <td>-2.088836</td>\n",
              "      <td>HINDI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 39 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e676a0a-d042-47a6-b729-1e2669ab95f4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8e676a0a-d042-47a6-b729-1e2669ab95f4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8e676a0a-d042-47a6-b729-1e2669ab95f4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0e0d98e2-e612-4131-8c57-56667190a70d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e0d98e2-e612-4131-8c57-56667190a70d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0e0d98e2-e612-4131-8c57-56667190a70d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_84ebc4cb-5372-412f-a471-1c32aacf0e3f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('combined_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_84ebc4cb-5372-412f-a471-1c32aacf0e3f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('combined_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_df"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, Conv1D, LSTM, Bidirectional, MultiHeadAttention, Flatten, LayerNormalization, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# ==============================\n",
        "# 1️⃣ Load Training Data\n",
        "# ==============================\n",
        "csv_file_path = \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/merged_data.csv\"\n",
        "df = pd.read_csv(csv_file_path)\n",
        "print(\"✅ Loaded training data!\")\n",
        "\n",
        "# ==============================\n",
        "# 2️⃣ Preprocess Data\n",
        "# ==============================\n",
        "X = df.drop(columns=['id', 'filename', 'file_url', 'gender', 'pincode', 'district',\n",
        "                     'stayYears', 'assertLanguage', 'languagesSpoken', 'state'], errors='ignore')\n",
        "y = df['assertLanguage']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-rZMqCXsHpF",
        "outputId": "dfbd9788-d4ae-4d3f-b58c-81c14c41db09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded training data!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "VfC7l2nVsejr",
        "outputId": "150ad6a6-7e20-4fdb-a17f-7e97c4a8ec81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
              "0 -301.82130  162.34149   3.773172  29.347368   5.833158  36.223263   \n",
              "1 -234.52022  143.98537 -16.144390   7.688753  -0.016806   6.717246   \n",
              "2 -318.37576  136.73366  20.810110  45.047370  -4.771094  27.556955   \n",
              "\n",
              "   feature_6  feature_7  feature_8  feature_9  ...  feature_28  feature_29  \\\n",
              "0 -13.055736   7.063834  -0.404653  -3.601685  ...   -0.477028   -1.981790   \n",
              "1 -24.379072   2.334164 -18.932920  -5.769550  ...   -4.614813    1.955276   \n",
              "2  -3.196370  15.037026   2.432315  -2.289925  ...   -2.471562    0.508572   \n",
              "\n",
              "   feature_30  feature_31  feature_32  feature_33  feature_34  feature_35  \\\n",
              "0   -2.183699   -1.061338    2.378047    1.560722    1.960453    2.480789   \n",
              "1   -1.191994   -0.626358    2.216004    1.909258   -0.185616    0.284626   \n",
              "2   -4.296451   -1.692242   -2.544844   -0.938026   -3.195067   -0.604838   \n",
              "\n",
              "   feature_36  feature_37  \n",
              "0    4.246184    3.377369  \n",
              "1    3.413281   -1.186310  \n",
              "2   -0.066298   -2.088836  \n",
              "\n",
              "[3 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c916c65-87d8-49a8-8b6c-0190492323f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_28</th>\n",
              "      <th>feature_29</th>\n",
              "      <th>feature_30</th>\n",
              "      <th>feature_31</th>\n",
              "      <th>feature_32</th>\n",
              "      <th>feature_33</th>\n",
              "      <th>feature_34</th>\n",
              "      <th>feature_35</th>\n",
              "      <th>feature_36</th>\n",
              "      <th>feature_37</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-301.82130</td>\n",
              "      <td>162.34149</td>\n",
              "      <td>3.773172</td>\n",
              "      <td>29.347368</td>\n",
              "      <td>5.833158</td>\n",
              "      <td>36.223263</td>\n",
              "      <td>-13.055736</td>\n",
              "      <td>7.063834</td>\n",
              "      <td>-0.404653</td>\n",
              "      <td>-3.601685</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.477028</td>\n",
              "      <td>-1.981790</td>\n",
              "      <td>-2.183699</td>\n",
              "      <td>-1.061338</td>\n",
              "      <td>2.378047</td>\n",
              "      <td>1.560722</td>\n",
              "      <td>1.960453</td>\n",
              "      <td>2.480789</td>\n",
              "      <td>4.246184</td>\n",
              "      <td>3.377369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-234.52022</td>\n",
              "      <td>143.98537</td>\n",
              "      <td>-16.144390</td>\n",
              "      <td>7.688753</td>\n",
              "      <td>-0.016806</td>\n",
              "      <td>6.717246</td>\n",
              "      <td>-24.379072</td>\n",
              "      <td>2.334164</td>\n",
              "      <td>-18.932920</td>\n",
              "      <td>-5.769550</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.614813</td>\n",
              "      <td>1.955276</td>\n",
              "      <td>-1.191994</td>\n",
              "      <td>-0.626358</td>\n",
              "      <td>2.216004</td>\n",
              "      <td>1.909258</td>\n",
              "      <td>-0.185616</td>\n",
              "      <td>0.284626</td>\n",
              "      <td>3.413281</td>\n",
              "      <td>-1.186310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-318.37576</td>\n",
              "      <td>136.73366</td>\n",
              "      <td>20.810110</td>\n",
              "      <td>45.047370</td>\n",
              "      <td>-4.771094</td>\n",
              "      <td>27.556955</td>\n",
              "      <td>-3.196370</td>\n",
              "      <td>15.037026</td>\n",
              "      <td>2.432315</td>\n",
              "      <td>-2.289925</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.471562</td>\n",
              "      <td>0.508572</td>\n",
              "      <td>-4.296451</td>\n",
              "      <td>-1.692242</td>\n",
              "      <td>-2.544844</td>\n",
              "      <td>-0.938026</td>\n",
              "      <td>-3.195067</td>\n",
              "      <td>-0.604838</td>\n",
              "      <td>-0.066298</td>\n",
              "      <td>-2.088836</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 38 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c916c65-87d8-49a8-8b6c-0190492323f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2c916c65-87d8-49a8-8b6c-0190492323f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2c916c65-87d8-49a8-8b6c-0190492323f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a3ad2ae4-7f11-4000-b480-1194ff2cf7e1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3ad2ae4-7f11-4000-b480-1194ff2cf7e1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a3ad2ae4-7f11-4000-b480-1194ff2cf7e1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a689a131-d872-43a6-b0b2-a8070be5f280\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_new')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a689a131-d872-43a6-b0b2-a8070be5f280 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X_new');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_new"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=pd.concat([X, X_new], ignore_index=True)\n",
        "y=pd.concat([y, y_new], ignore_index=True)"
      ],
      "metadata": {
        "id": "-1ry82JQsTII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "xeZaOBRxslV9",
        "outputId": "9983022a-ed7d-4b25-9362-fd9bb814df12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0             HINDI\n",
              "1             HINDI\n",
              "2             HINDI\n",
              "3             HINDI\n",
              "4             HINDI\n",
              "            ...    \n",
              "73982    RAJASTHANI\n",
              "73983    RAJASTHANI\n",
              "73984        TELUGU\n",
              "73985       MARATHI\n",
              "73986         HINDI\n",
              "Name: assertLanguage, Length: 73987, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>assertLanguage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HINDI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HINDI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HINDI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HINDI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HINDI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73982</th>\n",
              "      <td>RAJASTHANI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73983</th>\n",
              "      <td>RAJASTHANI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73984</th>\n",
              "      <td>TELUGU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73985</th>\n",
              "      <td>MARATHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73986</th>\n",
              "      <td>HINDI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>73987 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "LDMNdILIsiCQ",
        "outputId": "5e5e7782-8896-4491-cc26-b57f93ec420f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        feature_0   feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
              "0     -297.546265  120.581055  20.237211  59.388645  -0.672819 -14.173330   \n",
              "1     -260.200684  105.669434   8.691262  58.377419 -17.515112   4.168218   \n",
              "2     -234.857452   80.267685   2.636047   9.870395 -13.524202 -16.229780   \n",
              "3     -288.347992  136.035095   5.828763  57.002117 -23.706793   0.961969   \n",
              "4     -210.954956  106.860130   6.268232   9.759131 -21.126705 -12.630594   \n",
              "...           ...         ...        ...        ...        ...        ...   \n",
              "73982 -123.170074   79.047691   8.513207  70.706596 -10.343614 -10.557887   \n",
              "73983 -264.190826  116.151489   8.716024  31.138224 -12.527115  -1.554535   \n",
              "73984 -301.821300  162.341490   3.773172  29.347368   5.833158  36.223263   \n",
              "73985 -234.520220  143.985370 -16.144390   7.688753  -0.016806   6.717246   \n",
              "73986 -318.375760  136.733660  20.810110  45.047370  -4.771094  27.556955   \n",
              "\n",
              "       feature_6  feature_7  feature_8  feature_9  ...  feature_28  \\\n",
              "0     -29.306034 -17.202627 -15.284561 -21.358829  ...   20.510233   \n",
              "1     -24.531080 -25.229774 -23.366369 -30.466015  ...   21.712901   \n",
              "2     -23.384377 -12.242881 -20.520033 -13.439591  ...   18.724071   \n",
              "3     -14.126427 -52.532833  -8.909392  -9.687088  ...   21.278267   \n",
              "4     -23.158993 -16.264835 -22.510866 -14.486049  ...   22.391488   \n",
              "...          ...        ...        ...        ...  ...         ...   \n",
              "73982 -24.143688  -7.584201 -17.439257  -6.821399  ...   17.427161   \n",
              "73983 -10.416448  -9.566309 -14.856421 -13.804207  ...   19.511640   \n",
              "73984 -13.055736   7.063834  -0.404653  -3.601685  ...   -0.477028   \n",
              "73985 -24.379072   2.334164 -18.932920  -5.769550  ...   -4.614813   \n",
              "73986  -3.196370  15.037026   2.432315  -2.289925  ...   -2.471562   \n",
              "\n",
              "       feature_29  feature_30  feature_31  feature_32  feature_33  feature_34  \\\n",
              "0       24.213826   29.381877   14.743478    0.033548    0.011172   -0.025681   \n",
              "1       22.469807   29.498849   17.961922    0.068505   -0.003371   -0.059312   \n",
              "2       21.145171   23.260481   31.949563    0.014118   -0.005542    0.056249   \n",
              "3       25.709413   35.111273   14.684528    0.025488    0.024609    0.015288   \n",
              "4       22.408556   23.591935   26.764527    0.068178    0.010451    0.221548   \n",
              "...           ...         ...         ...         ...         ...         ...   \n",
              "73982   20.728594   20.213408   28.891565   -0.042445    0.040650   -0.133627   \n",
              "73983   19.491819   19.868303   20.756192   -0.023760    0.033770    0.003179   \n",
              "73984   -1.981790   -2.183699   -1.061338    2.378047    1.560722    1.960453   \n",
              "73985    1.955276   -1.191994   -0.626358    2.216004    1.909258   -0.185616   \n",
              "73986    0.508572   -4.296451   -1.692242   -2.544844   -0.938026   -3.195067   \n",
              "\n",
              "       feature_35  feature_36  feature_37  \n",
              "0       -0.073708   -0.039746    0.011990  \n",
              "1       -0.125556   -0.026395   -0.015464  \n",
              "2       -0.050925    0.005657    0.001793  \n",
              "3       -0.115441   -0.032343    0.001734  \n",
              "4       -0.095666    0.060192   -0.007815  \n",
              "...           ...         ...         ...  \n",
              "73982    0.140569    0.049548    0.012495  \n",
              "73983   -0.099469   -0.000492   -0.029672  \n",
              "73984    2.480789    4.246184    3.377369  \n",
              "73985    0.284626    3.413281   -1.186310  \n",
              "73986   -0.604838   -0.066298   -2.088836  \n",
              "\n",
              "[73987 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7964a3f6-d411-423f-8865-850aeb17a599\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_28</th>\n",
              "      <th>feature_29</th>\n",
              "      <th>feature_30</th>\n",
              "      <th>feature_31</th>\n",
              "      <th>feature_32</th>\n",
              "      <th>feature_33</th>\n",
              "      <th>feature_34</th>\n",
              "      <th>feature_35</th>\n",
              "      <th>feature_36</th>\n",
              "      <th>feature_37</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-297.546265</td>\n",
              "      <td>120.581055</td>\n",
              "      <td>20.237211</td>\n",
              "      <td>59.388645</td>\n",
              "      <td>-0.672819</td>\n",
              "      <td>-14.173330</td>\n",
              "      <td>-29.306034</td>\n",
              "      <td>-17.202627</td>\n",
              "      <td>-15.284561</td>\n",
              "      <td>-21.358829</td>\n",
              "      <td>...</td>\n",
              "      <td>20.510233</td>\n",
              "      <td>24.213826</td>\n",
              "      <td>29.381877</td>\n",
              "      <td>14.743478</td>\n",
              "      <td>0.033548</td>\n",
              "      <td>0.011172</td>\n",
              "      <td>-0.025681</td>\n",
              "      <td>-0.073708</td>\n",
              "      <td>-0.039746</td>\n",
              "      <td>0.011990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-260.200684</td>\n",
              "      <td>105.669434</td>\n",
              "      <td>8.691262</td>\n",
              "      <td>58.377419</td>\n",
              "      <td>-17.515112</td>\n",
              "      <td>4.168218</td>\n",
              "      <td>-24.531080</td>\n",
              "      <td>-25.229774</td>\n",
              "      <td>-23.366369</td>\n",
              "      <td>-30.466015</td>\n",
              "      <td>...</td>\n",
              "      <td>21.712901</td>\n",
              "      <td>22.469807</td>\n",
              "      <td>29.498849</td>\n",
              "      <td>17.961922</td>\n",
              "      <td>0.068505</td>\n",
              "      <td>-0.003371</td>\n",
              "      <td>-0.059312</td>\n",
              "      <td>-0.125556</td>\n",
              "      <td>-0.026395</td>\n",
              "      <td>-0.015464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-234.857452</td>\n",
              "      <td>80.267685</td>\n",
              "      <td>2.636047</td>\n",
              "      <td>9.870395</td>\n",
              "      <td>-13.524202</td>\n",
              "      <td>-16.229780</td>\n",
              "      <td>-23.384377</td>\n",
              "      <td>-12.242881</td>\n",
              "      <td>-20.520033</td>\n",
              "      <td>-13.439591</td>\n",
              "      <td>...</td>\n",
              "      <td>18.724071</td>\n",
              "      <td>21.145171</td>\n",
              "      <td>23.260481</td>\n",
              "      <td>31.949563</td>\n",
              "      <td>0.014118</td>\n",
              "      <td>-0.005542</td>\n",
              "      <td>0.056249</td>\n",
              "      <td>-0.050925</td>\n",
              "      <td>0.005657</td>\n",
              "      <td>0.001793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-288.347992</td>\n",
              "      <td>136.035095</td>\n",
              "      <td>5.828763</td>\n",
              "      <td>57.002117</td>\n",
              "      <td>-23.706793</td>\n",
              "      <td>0.961969</td>\n",
              "      <td>-14.126427</td>\n",
              "      <td>-52.532833</td>\n",
              "      <td>-8.909392</td>\n",
              "      <td>-9.687088</td>\n",
              "      <td>...</td>\n",
              "      <td>21.278267</td>\n",
              "      <td>25.709413</td>\n",
              "      <td>35.111273</td>\n",
              "      <td>14.684528</td>\n",
              "      <td>0.025488</td>\n",
              "      <td>0.024609</td>\n",
              "      <td>0.015288</td>\n",
              "      <td>-0.115441</td>\n",
              "      <td>-0.032343</td>\n",
              "      <td>0.001734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-210.954956</td>\n",
              "      <td>106.860130</td>\n",
              "      <td>6.268232</td>\n",
              "      <td>9.759131</td>\n",
              "      <td>-21.126705</td>\n",
              "      <td>-12.630594</td>\n",
              "      <td>-23.158993</td>\n",
              "      <td>-16.264835</td>\n",
              "      <td>-22.510866</td>\n",
              "      <td>-14.486049</td>\n",
              "      <td>...</td>\n",
              "      <td>22.391488</td>\n",
              "      <td>22.408556</td>\n",
              "      <td>23.591935</td>\n",
              "      <td>26.764527</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.010451</td>\n",
              "      <td>0.221548</td>\n",
              "      <td>-0.095666</td>\n",
              "      <td>0.060192</td>\n",
              "      <td>-0.007815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73982</th>\n",
              "      <td>-123.170074</td>\n",
              "      <td>79.047691</td>\n",
              "      <td>8.513207</td>\n",
              "      <td>70.706596</td>\n",
              "      <td>-10.343614</td>\n",
              "      <td>-10.557887</td>\n",
              "      <td>-24.143688</td>\n",
              "      <td>-7.584201</td>\n",
              "      <td>-17.439257</td>\n",
              "      <td>-6.821399</td>\n",
              "      <td>...</td>\n",
              "      <td>17.427161</td>\n",
              "      <td>20.728594</td>\n",
              "      <td>20.213408</td>\n",
              "      <td>28.891565</td>\n",
              "      <td>-0.042445</td>\n",
              "      <td>0.040650</td>\n",
              "      <td>-0.133627</td>\n",
              "      <td>0.140569</td>\n",
              "      <td>0.049548</td>\n",
              "      <td>0.012495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73983</th>\n",
              "      <td>-264.190826</td>\n",
              "      <td>116.151489</td>\n",
              "      <td>8.716024</td>\n",
              "      <td>31.138224</td>\n",
              "      <td>-12.527115</td>\n",
              "      <td>-1.554535</td>\n",
              "      <td>-10.416448</td>\n",
              "      <td>-9.566309</td>\n",
              "      <td>-14.856421</td>\n",
              "      <td>-13.804207</td>\n",
              "      <td>...</td>\n",
              "      <td>19.511640</td>\n",
              "      <td>19.491819</td>\n",
              "      <td>19.868303</td>\n",
              "      <td>20.756192</td>\n",
              "      <td>-0.023760</td>\n",
              "      <td>0.033770</td>\n",
              "      <td>0.003179</td>\n",
              "      <td>-0.099469</td>\n",
              "      <td>-0.000492</td>\n",
              "      <td>-0.029672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73984</th>\n",
              "      <td>-301.821300</td>\n",
              "      <td>162.341490</td>\n",
              "      <td>3.773172</td>\n",
              "      <td>29.347368</td>\n",
              "      <td>5.833158</td>\n",
              "      <td>36.223263</td>\n",
              "      <td>-13.055736</td>\n",
              "      <td>7.063834</td>\n",
              "      <td>-0.404653</td>\n",
              "      <td>-3.601685</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.477028</td>\n",
              "      <td>-1.981790</td>\n",
              "      <td>-2.183699</td>\n",
              "      <td>-1.061338</td>\n",
              "      <td>2.378047</td>\n",
              "      <td>1.560722</td>\n",
              "      <td>1.960453</td>\n",
              "      <td>2.480789</td>\n",
              "      <td>4.246184</td>\n",
              "      <td>3.377369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73985</th>\n",
              "      <td>-234.520220</td>\n",
              "      <td>143.985370</td>\n",
              "      <td>-16.144390</td>\n",
              "      <td>7.688753</td>\n",
              "      <td>-0.016806</td>\n",
              "      <td>6.717246</td>\n",
              "      <td>-24.379072</td>\n",
              "      <td>2.334164</td>\n",
              "      <td>-18.932920</td>\n",
              "      <td>-5.769550</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.614813</td>\n",
              "      <td>1.955276</td>\n",
              "      <td>-1.191994</td>\n",
              "      <td>-0.626358</td>\n",
              "      <td>2.216004</td>\n",
              "      <td>1.909258</td>\n",
              "      <td>-0.185616</td>\n",
              "      <td>0.284626</td>\n",
              "      <td>3.413281</td>\n",
              "      <td>-1.186310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73986</th>\n",
              "      <td>-318.375760</td>\n",
              "      <td>136.733660</td>\n",
              "      <td>20.810110</td>\n",
              "      <td>45.047370</td>\n",
              "      <td>-4.771094</td>\n",
              "      <td>27.556955</td>\n",
              "      <td>-3.196370</td>\n",
              "      <td>15.037026</td>\n",
              "      <td>2.432315</td>\n",
              "      <td>-2.289925</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.471562</td>\n",
              "      <td>0.508572</td>\n",
              "      <td>-4.296451</td>\n",
              "      <td>-1.692242</td>\n",
              "      <td>-2.544844</td>\n",
              "      <td>-0.938026</td>\n",
              "      <td>-3.195067</td>\n",
              "      <td>-0.604838</td>\n",
              "      <td>-0.066298</td>\n",
              "      <td>-2.088836</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>73987 rows × 38 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7964a3f6-d411-423f-8865-850aeb17a599')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7964a3f6-d411-423f-8865-850aeb17a599 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7964a3f6-d411-423f-8865-850aeb17a599');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ea9ddbec-060c-4407-b3bc-a5fa69924e0d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea9ddbec-060c-4407-b3bc-a5fa69924e0d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ea9ddbec-060c-4407-b3bc-a5fa69924e0d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_27522ede-959a-4884-bddb-5d7270a16251\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_27522ede-959a-4884-bddb-5d7270a16251 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mha+bIlstm+CNN"
      ],
      "metadata": {
        "id": "2OaTDoBpluzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Encode labels\n",
        "language_encoder = LabelEncoder()\n",
        "y = language_encoder.fit_transform(y)\n",
        "\n",
        "# Save Label Encoder\n",
        "#joblib.dump(language_encoder, r\"C:\\Users\\NMIMS.Student\\Desktop\\vaani\\language_encoder.pkl\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
        "\n",
        "# Save training feature names\n",
        "train_feature_names = list(X_train.columns)\n",
        "#joblib.dump(train_feature_names, r\"C:\\Users\\NMIMS.Student\\Desktop\\vaani\\train_feature_names.pkl\")\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Save Scaler\n",
        "#joblib.dump(scaler, r\"C:\\Users\\NMIMS.Student\\Desktop\\vaani\\scaler.pkl\")\n",
        "\n",
        "# Reshape for CNN + BiLSTM + Attention\n",
        "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
        "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train_categorical = to_categorical(y_train, num_classes=len(language_encoder.classes_))\n",
        "y_test_categorical = to_categorical(y_test, num_classes=len(language_encoder.classes_))\n",
        "\n",
        "print(\"✅ Preprocessing done!\")\n",
        "\n",
        "# ==============================\n",
        "# 3️⃣ Define Hybrid Model: CNN + BiLSTM + Multi-Head Attention\n",
        "# ==============================\n",
        "input_layer = Input(shape=(X_train.shape[1], 1))\n",
        "\n",
        "# CNN Feature Extraction\n",
        "cnn = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "cnn = BatchNormalization()(cnn)\n",
        "\n",
        "# BiLSTM Layer\n",
        "bilstm = Bidirectional(LSTM(64, return_sequences=True, dropout=0.3))(cnn)\n",
        "\n",
        "# Multi-Head Attention\n",
        "attention_output = MultiHeadAttention(num_heads=4, key_dim=32)(bilstm, bilstm)\n",
        "attention_output = LayerNormalization(epsilon=1e-6)(attention_output)\n",
        "\n",
        "# Flatten and Fully Connected Layers\n",
        "x = Flatten()(attention_output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "output_layer = Dense(len(language_encoder.classes_), activation='softmax')(x)\n",
        "\n",
        "# Create Model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# ==============================\n",
        "# 4️⃣ Train the Model\n",
        "# ==============================\n",
        "history = model.fit(\n",
        "    X_train_reshaped, y_train_categorical,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_reshaped, y_test_categorical),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# 5️⃣ Save Model\n",
        "# ==============================\n",
        "model.save(\"/content/drive/MyDrive/my_trained_hybrid_model_MHA_BILSTM_CNN.h5\")\n",
        "print(\"✅ Model training complete and saved!\")\n"
      ],
      "metadata": {
        "id": "ybt9LESjamja",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "15d3f3ac-4cc9-47bb-b35f-a5132526fce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Preprocessing done!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Conv1D' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-0ceeae3ee4ab>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# CNN Feature Extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Conv1D' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(language_encoder, \"/content/drive/MyDrive/language_encoder_mha_bilstm_cnn.pkl\")\n",
        "joblib.dump(train_feature_names, \"/content/drive/MyDrive/train_feature_names_mha_bilstm_cnn.pkl\")\n",
        "joblib.dump(scaler, \"/content/drive/MyDrive/scaler_mha_bilstm_cnn.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdFBDV7TuKIa",
        "outputId": "e03ac7de-6fb2-427d-c1dd-ffb003bb2801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/scaler_mha_bilstm_cnn.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# ==============================\n",
        "# 1️⃣ Load Saved Model & Encoders\n",
        "# ==============================\n",
        "model_path = \"/content/drive/MyDrive/my_trained_hybrid_model_MHA_BILSTM_CNN.h5\"\n",
        "encoder_path = \"/content/drive/MyDrive/language_encoder_mha_bilstm_cnn.pkl\"\n",
        "scaler_path = \"/content/drive/MyDrive/scaler_mha_bilstm_cnn.pkl\"\n",
        "feature_names_path = \"/content/drive/MyDrive/train_feature_names_mha_bilstm_cnn.pkl\"\n",
        "\n",
        "# Load Model\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "print(\"✅ Model loaded successfully!\")\n",
        "\n",
        "# Load Label Encoder\n",
        "if os.path.exists(encoder_path):\n",
        "    language_encoder = joblib.load(encoder_path)\n",
        "else:\n",
        "    raise FileNotFoundError(\"🚨 Label Encoder file not found. Run training script first.\")\n",
        "\n",
        "# Load Scaler\n",
        "if os.path.exists(scaler_path):\n",
        "    scaler = joblib.load(scaler_path)\n",
        "else:\n",
        "    raise FileNotFoundError(\"🚨 Scaler file not found. Run training script first.\")\n",
        "\n",
        "# Load Training Feature Names\n",
        "if os.path.exists(feature_names_path):\n",
        "    train_feature_names = joblib.load(feature_names_path)\n",
        "else:\n",
        "    raise FileNotFoundError(\"🚨 Training feature names file not found. Run training script first.\")\n",
        "\n",
        "# ==============================\n",
        "# 2️⃣ Load and Process Test Data\n",
        "# ==============================\n",
        "test_csv_path = \"/content/drive/MyDrive/IE3 Lab/Sakshi PC/test_audio_final.csv\"\n",
        "df_test = pd.read_csv(test_csv_path)\n",
        "\n",
        "# Extract actual labels before dropping columns\n",
        "actual_languages = df_test['assertLanguage'].tolist()\n",
        "\n",
        "# Drop unnecessary columns\n",
        "drop_columns = ['id', 'filename', 'file_url', 'gender', 'pincode', 'district',\n",
        "                'stayYears', 'assertLanguage', 'languagesSpoken', 'state']\n",
        "df_test = df_test.drop(columns=[col for col in drop_columns if col in df_test.columns])\n",
        "\n",
        "# Ensure test data has same features as training\n",
        "for feature in train_feature_names:\n",
        "    if feature not in df_test.columns:\n",
        "        df_test[feature] = 0\n",
        "\n",
        "# Reorder columns to match training\n",
        "df_test = df_test[train_feature_names]\n",
        "\n",
        "# ==============================\n",
        "# 3️⃣ Scale and Reshape Test Data\n",
        "# ==============================\n",
        "X_test_new = scaler.transform(df_test)\n",
        "X_test_reshaped_new = X_test_new.reshape(X_test_new.shape[0], X_test_new.shape[1], 1)\n",
        "\n",
        "# ==============================\n",
        "# 4️⃣ Make Predictions\n",
        "# ==============================\n",
        "predictions = model.predict(X_test_reshaped_new)\n",
        "predicted_class_indices = np.argmax(predictions, axis=1)\n",
        "predicted_labels = language_encoder.inverse_transform(predicted_class_indices)\n",
        "\n",
        "# ==============================\n",
        "# 5️⃣ Print Predictions vs Actual Labels\n",
        "# ==============================\n",
        "print(\"\\n🎯 Model Predictions vs Actual Labels:\")\n",
        "print(f\"{'Sample':<10}{'Actual':<20}{'Predicted':<20}\")\n",
        "\n",
        "for i, (actual, predicted) in enumerate(zip(actual_languages, predicted_labels)):\n",
        "    print(f\"{i+1:<10}{actual:<20}{predicted:<20}\")\n",
        "\n",
        "# ==============================\n",
        "# 6️⃣ Compute Accuracy\n",
        "# ==============================\n",
        "y_test_encoded = language_encoder.transform(actual_languages)\n",
        "correct_predictions = sum(np.array(predicted_labels) == np.array(actual_languages))\n",
        "accuracy = correct_predictions / len(actual_languages)\n",
        "\n",
        "print(f\"\\n✅ Final Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "YMLruHS-amnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ece1fe1-b6b7-45de-bc15-5649a99e480d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded successfully!\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 803ms/step\n",
            "\n",
            "🎯 Model Predictions vs Actual Labels:\n",
            "Sample    Actual              Predicted           \n",
            "1         HINDI               HINDI               \n",
            "2         HINDI               HINDI               \n",
            "3         HINDI               HINDI               \n",
            "4         HINDI               HINDI               \n",
            "5         HINDI               HINDI               \n",
            "6         HINDI               MARATHI             \n",
            "7         MARWARI             RAJASTHANI          \n",
            "8         RAJASTHANI          RAJASTHANI          \n",
            "9         MARWARI             RAJASTHANI          \n",
            "10        MARWARI             RAJASTHANI          \n",
            "11        RAJASTHANI          RAJASTHANI          \n",
            "12        HINDI               HINDI               \n",
            "13        HINDI               HINDI               \n",
            "14        HINDI               HINDI               \n",
            "15        HINDI               HINDI               \n",
            "16        HINDI               HINDI               \n",
            "17        HINDI               HINDI               \n",
            "18        HINDI               HINDI               \n",
            "19        HINDI               HINDI               \n",
            "20        HINDI               HINDI               \n",
            "21        MARATHI             MARATHI             \n",
            "22        HINDI               CHATTISGARHI        \n",
            "23        KONKANI             HINDI               \n",
            "24        KONKANI             KANNADA             \n",
            "25        HINDI               KANNADA             \n",
            "26        HINDI               KANNADA             \n",
            "27        HINDI               KANNADA             \n",
            "28        HINDI               HINDI               \n",
            "29        HINDI               KANNADA             \n",
            "30        HINDI               KANNADA             \n",
            "31        HINDI               MARATHI             \n",
            "32        HINDI               RAJASTHANI          \n",
            "33        HINDI               HINDI               \n",
            "34        HINDI               RAJASTHANI          \n",
            "35        HINDI               TELUGU              \n",
            "36        HINDI               MARATHI             \n",
            "37        HINDI               HINDI               \n",
            "38        HINDI               HINDI               \n",
            "39        HINDI               HINDI               \n",
            "40        HINDI               HINDI               \n",
            "41        HINDI               HINDI               \n",
            "42        HINDI               HINDI               \n",
            "43        HINDI               HINDI               \n",
            "44        HINDI               HINDI               \n",
            "45        HINDI               MARATHI             \n",
            "\n",
            "✅ Final Test Accuracy: 0.6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: mount google drive import gooogle\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDr8Ds1fitmT",
        "outputId": "4734a57a-992c-495d-a938-334ceb7c3a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(language_encoder, \"/content/drive/MyDrive/language_encoder_mha_bilstm_cnn.pkl\")\n",
        "joblib.dump(train_feature_names, \"/content/drive/MyDrive/train_feature_names_mha_bilstm_cnn.pkl\")\n",
        "joblib.dump(scaler, \"/content/drive/MyDrive/scaler_mha_bilstm_cnn.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "XmZWDNIBju4S",
        "outputId": "cb22d6cf-a9f8-4c2a-d660-c7dc57a29927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'language_encoder' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e2e0035efa62>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/language_encoder_mha_bilstm_cnn.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/train_feature_names_mha_bilstm_cnn.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/scaler_mha_bilstm_cnn.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'language_encoder' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kecqPbk0jMHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QFtdXn5p9NVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "\n",
        "# Load the Keras model\n",
        "model = load_model(\"/content/drive/MyDrive/my_trained_hybrid_model_MHA_BILSTM_CNN.h5\", compile=False)\n",
        "language_encoder = joblib.load(\"/content/drive/MyDrive/language_encoder_mha_bilstm_cnn.pkl\")\n",
        "train_feature_names = joblib.load(\"/content/drive/MyDrive/train_feature_names_mha_bilstm_cnn.pkl\")\n",
        "scaler = joblib.load(\"/content/drive/MyDrive/scaler_mha_bilstm_cnn.pkl\")\n",
        "\n",
        "sahitya=pd.read_csv(\"/content/drive/MyDrive/new test audios/Kimaya's Audio Features.csv\")\n",
        "sahitya.columns = [f\"feature_{i}\" for i in range(len(sahitya.columns))]\n",
        "sahitya_new = scaler.transform(sahitya)\n",
        "sahitya_reshaped_new = sahitya_new.reshape(sahitya_new.shape[0], sahitya_new.shape[1], 1)\n",
        "predictions = model.predict(sahitya_reshaped_new)\n",
        "predictions\n",
        "predicted_class_indices = np.argmax(predictions, axis=1)\n",
        "predicted_class_indices\n",
        "predicted_labels = language_encoder.inverse_transform(predicted_class_indices)\n",
        "predicted_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96LRzdg65UgU",
        "outputId": "3ca8935c-b011-4bd0-9d73-b2ad11a9ca37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['HINDI'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sahitya.columns = [f\"feature_{i}\" for i in range(len(sahitya.columns))]\n",
        "sahitya_new = scaler.transform(sahitya)\n",
        "sahitya_reshaped_new = sahitya_new.reshape(sahitya_new.shape[0], sahitya_new.shape[1], 1)"
      ],
      "metadata": {
        "id": "NA5MN26I5t3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(sahitya_reshaped_new)\n",
        "predicted_class_indices = np.argmax(predictions, axis=1)\n",
        "predicted_labels = language_encoder.inverse_transform(predicted_class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNHPx6Bq59xp",
        "outputId": "6874a5ae-5fa8-4399-fb85-474a7298d59d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-2AbfwJ6IGF",
        "outputId": "fb94dca4-5a6b-4ab3-f514-02cdf3ff6a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['MARATHI'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#STREAMLIT\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import os\n",
        "import joblib\n",
        "import requests\n",
        "from googletrans import Translator\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "import google.generativeai as genai\n",
        "from PyPDF2.errors import PdfReadError\n",
        "import tempfile\n",
        "from dotenv import load_dotenv\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
        "    st.error(\"Google API key not loaded!\")\n",
        "\n",
        "# Initialize translator\n",
        "translator = Translator()\n",
        "\n",
        "# Configuration\n",
        "LANGUAGE_DICT = {'HINDI': 'hi-IN', 'MARATHI': 'mr-IN'}\n",
        "SARVAM_API_KEY = \"ff014cc1-c60d-4304-b097-76e135ab6ac1\"\n",
        "\n",
        "# ========== CORE FUNCTIONS ==========\n",
        "\n",
        "def get_pdf_text(pdf_docs):\n",
        "    \"\"\"Extract text from uploaded PDF files\"\"\"\n",
        "    text = \"\"\n",
        "    for pdf in pdf_docs:\n",
        "        try:\n",
        "            pdf_reader = PdfReader(pdf)\n",
        "            for page in pdf_reader.pages:\n",
        "                text += page.extract_text()\n",
        "        except Exception as e:\n",
        "            st.warning(f\"Couldn't read {pdf.name}: {str(e)}\")\n",
        "    return text\n",
        "\n",
        "def get_text_chunks(text):\n",
        "    \"\"\"Split text into chunks for processing\"\"\"\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=10000,\n",
        "        chunk_overlap=1000\n",
        "    )\n",
        "    return text_splitter.split_text(text)\n",
        "\n",
        "def get_vector_store(text_chunks):\n",
        "    \"\"\"Create and save vector store\"\"\"\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "    vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)\n",
        "    vector_store.save_local(\"faiss_index\")\n",
        "\n",
        "def get_conversational_chain():\n",
        "    \"\"\"Create QA chain with prompt template\"\"\"\n",
        "    prompt_template = \"\"\"\n",
        "    Answer the question from the context. If answer isn't in context,\n",
        "    say \"answer not available in context\". Don't make up answers.\n",
        "\n",
        "    Context:\\n{context}\\n\n",
        "    Question:\\n{question}\\n\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "    model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.3)\n",
        "    prompt = PromptTemplate(template=prompt_template,\n",
        "                          input_variables=[\"context\", \"question\"])\n",
        "    return load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
        "\n",
        "def get_answer(question):\n",
        "    \"\"\"Get answer from vector store\"\"\"\n",
        "    try:\n",
        "        embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "        new_db = FAISS.load_local(\"faiss_index\", embeddings,\n",
        "                                 allow_dangerous_deserialization=True)\n",
        "        docs = new_db.similarity_search(question)\n",
        "        chain = get_conversational_chain()\n",
        "        response = chain({\"input_documents\": docs, \"question\": question},\n",
        "                        return_only_outputs=True)\n",
        "        return response[\"output_text\"]\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def extract_features(audio_file):\n",
        "    \"\"\"Extract exactly 38 MFCC features to match the scaler's expectations\"\"\"\n",
        "    y, sr = librosa.load(audio_file, sr=None)\n",
        "\n",
        "    # Extract only MFCCs with 38 coefficients\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=38)\n",
        "\n",
        "    # Take mean across time and flatten to 1D array\n",
        "    features = np.mean(mfccs.T, axis=0)\n",
        "\n",
        "    return features\n",
        "\n",
        "def speech_to_text(audio_path, language_code):\n",
        "    \"\"\"Convert speech to text using Sarvam API\"\"\"\n",
        "    url = \"https://api.sarvam.ai/speech-to-text\"\n",
        "    headers = {'api-subscription-key': SARVAM_API_KEY}\n",
        "    payload = {\n",
        "        'model': 'saarika:v1',\n",
        "        'language_code': LANGUAGE_DICT.get(language_code, 'hi-IN'),\n",
        "        'with_timesteps': 'false'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        with open(audio_path, 'rb') as f:\n",
        "            files = [('file', (os.path.basename(audio_path), f, 'audio/wav'))]\n",
        "            response = requests.post(url, headers=headers, data=payload, files=files)\n",
        "            return response.json().get('text', '') if response.status_code == 200 else None\n",
        "    except Exception as e:\n",
        "        st.error(f\"API error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "@st.cache_resource\n",
        "def load_language_models():\n",
        "    \"\"\"Load all language detection models\"\"\"\n",
        "    try:\n",
        "        return {\n",
        "            'scaler': joblib.load(r\"D:\\Nidhi\\Audio chatbot\\scaler.pkl\"),\n",
        "            'encoder': joblib.load(r\"D:\\Nidhi\\Audio chatbot\\label_encoder.pkl\"),\n",
        "            'ensemble': joblib.load(r\"D:\\Nidhi\\Audio chatbot\\ensemble_language_predictor.pkl\"),\n",
        "            'models': {\n",
        "                'mha': load_model(r\"D:\\Nidhi\\Audio chatbot\\MHA.h5\"),\n",
        "                'bilstm': load_model(r\"D:\\Nidhi\\Audio chatbot\\MHA Bilstm.h5\"),\n",
        "                'cnn': load_model(r\"D:\\Nidhi\\Audio chatbot\\Final_CNN_BiLSTM_MHA_Model.h5\")\n",
        "            }\n",
        "        }\n",
        "    except Exception as e:\n",
        "        st.error(f\"Model loading failed: {str(e)}\")\n",
        "        return None\n",
        "def detect_language(features, models_dict):\n",
        "    try:\n",
        "        # Ensure we have exactly 38 features\n",
        "        if len(features) != 38:\n",
        "            raise ValueError(f\"Expected 38 features, got {len(features)}\")\n",
        "\n",
        "        # Reshape for scaler (n_samples=1, n_features=38)\n",
        "        features = np.array(features).reshape(1, -1)\n",
        "\n",
        "        # Scale features\n",
        "        features_scaled = models_dict['scaler'].transform(features)\n",
        "\n",
        "        # Prepare inputs for each model\n",
        "        X_mha = features_scaled.reshape(1, 1, 38)  # (batch, timesteps, features)\n",
        "        X_cnn = features_scaled.reshape(1, 38, 1)   # (batch, features, channels)\n",
        "\n",
        "        # Get predictions\n",
        "        pred_mha = models_dict['models']['mha'].predict(X_mha, verbose=0)\n",
        "        pred_bilstm = models_dict['models']['bilstm'].predict(X_mha, verbose=0)\n",
        "        pred_cnn = models_dict['models']['cnn'].predict(X_cnn, verbose=0)\n",
        "\n",
        "        # Combine predictions\n",
        "        ensemble_input = np.concatenate([pred_mha, pred_bilstm, pred_cnn], axis=1)\n",
        "        final_pred = models_dict['ensemble'].predict(ensemble_input)\n",
        "\n",
        "        return models_dict['encoder'].inverse_transform(final_pred)[0]\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Detection Error: {str(e)}\")\n",
        "        st.error(f\"Input shape: {features.shape if 'features' in locals() else 'N/A'}\")\n",
        "        return None\n",
        "# ========== STREAMLIT APP ==========\n",
        "\n",
        "def main():\n",
        "    st.set_page_config(\"Multilingual Audio Q&A System\", layout=\"wide\")\n",
        "    st.title(\"🎙️ Multilingual Audio Q&A System\")\n",
        "\n",
        "    if \"chat_history\" not in st.session_state:\n",
        "        st.session_state.chat_history = []\n",
        "\n",
        "    models_dict = load_language_models()\n",
        "\n",
        "    # Sidebar\n",
        "    with st.sidebar:\n",
        "        st.header(\"📂 Knowledge Base\")\n",
        "        uploaded_files = st.file_uploader(\"Upload PDFs\",\n",
        "                                        accept_multiple_files=True,\n",
        "                                        type=[\"pdf\"])\n",
        "        if uploaded_files:\n",
        "            with st.spinner(\"Processing...\"):\n",
        "                raw_text = get_pdf_text(uploaded_files)\n",
        "                if raw_text:\n",
        "                    get_vector_store(get_text_chunks(raw_text))\n",
        "                    st.success(\"Knowledge base ready!\")\n",
        "\n",
        "    # Main content\n",
        "    col1, col2 = st.columns([1, 2])\n",
        "\n",
        "    with col1:\n",
        "        st.header(\"🎤 Ask Question\")\n",
        "        audio_file = st.file_uploader(\"Upload WAV\", type=[\"wav\"])\n",
        "\n",
        "        if audio_file and models_dict:\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as tmp:\n",
        "                tmp.write(audio_file.read())\n",
        "                audio_path = tmp.name\n",
        "\n",
        "            with st.spinner(\"Analyzing...\"):\n",
        "                try:\n",
        "                    features = extract_features(audio_path)\n",
        "                    language = detect_language(features, models_dict)\n",
        "                    if language:\n",
        "                        st.success(f\"Language: {language}\")\n",
        "                        if question := speech_to_text(audio_path, language):\n",
        "                            st.session_state.chat_history.append({\n",
        "                                \"role\": \"user\",\n",
        "                                \"content\": question,\n",
        "                                \"language\": language\n",
        "                            })\n",
        "                finally:\n",
        "                    os.unlink(audio_path)\n",
        "\n",
        "    with col2:\n",
        "        st.header(\"💬 Conversation\")\n",
        "        for msg in st.session_state.chat_history:\n",
        "            with st.chat_message(msg[\"role\"]):\n",
        "                st.write(msg[\"content\"])\n",
        "\n",
        "        if st.session_state.chat_history and st.session_state.chat_history[-1][\"role\"] == \"user\":\n",
        "            last = st.session_state.chat_history[-1]\n",
        "            answer = get_answer(last[\"content\"])\n",
        "\n",
        "            if last[\"language\"] != \"ENGLISH\":\n",
        "                try:\n",
        "                    answer = translator.translate(answer, src='en', dest=last[\"language\"].lower()).text\n",
        "                except:\n",
        "                    answer += \" (translation failed)\"\n",
        "\n",
        "            st.session_state.chat_history.append({\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": answer,\n",
        "                \"language\": last[\"language\"]\n",
        "            })\n",
        "            st.rerun()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "zlXNucK7tzB8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}